[
  {
    "id": "ISSUE-1712",
    "title": "Migrate from Elasticsearch 7.x to 8.x",
    "text": "Description: Current Elasticsearch cluster running 7.17 which reaches EOL in Q1 2026. Need to upgrade to 8.x to get security updates and new features.\n\nPlanning:\n- 3-node cluster with 500GB data per node\n- 15M documents across 8 indices\n- Zero-downtime upgrade required\n\nMigration Steps:\n1. Set up parallel 8.x cluster\n2. Configure cross-cluster replication\n3. Update application code for breaking changes\n4. Gradual traffic migration using feature flags\n5. Decommission 7.x cluster\n\nComments:\n- @david_data: Main breaking change is removal of mapping types\n- @sarah_dev: API client library needs upgrade from elasticsearch-py 7.x to 8.x\n- @john_backend: Testing pagination changes, from/size behavior different in 8.x\n- @alex_devops: Provisioned new cluster in staging, ready for testing\n- @maria_frontend: No frontend changes needed, API contract stays same\n\nCurrent Status: Staging migration successful. PR-598 contains all code changes. Planning production migration for next weekend.",
    "url": "https://internal-git.techcorp.com/issues/1712",
    "type": "issue",
    "status": "in_progress",
    "priority": "medium",
    "assignee": "david_data",
    "created_date": "2025-09-01",
    "resolved_date": null,
    "labels": ["infrastructure", "elasticsearch", "migration", "upgrade"],
    "related_pr": "PR-598"
  },
  {
    "id": "RFC-038",
    "title": "API Versioning Strategy and Deprecation Policy",
    "text": "Abstract: Establishes a formal API versioning strategy and deprecation policy to maintain backward compatibility while enabling API evolution.\n\nProblem Statement:\n- Current API has breaking changes in minor releases\n- No clear deprecation timeline for endpoints\n- Customers complain about unexpected breaking changes\n- Support burden from maintaining old API behavior\n\nProposed Versioning Strategy:\n- Semantic versioning: MAJOR.MINOR.PATCH\n- URL-based versioning: /api/v1, /api/v2, etc.\n- Header-based version override: X-API-Version: 2.1\n- Maintain 2 major versions simultaneously\n\nDeprecation Policy:\n1. Announce deprecation 6 months in advance\n2. Add deprecation warnings in response headers\n3. Update documentation with migration guide\n4. Send email notifications to affected users\n5. Sunset endpoint after 6-month grace period\n\nImplementation:\n- API version middleware to route requests\n- Automated deprecation header injection\n- Deprecation tracking dashboard\n- User notification system integration\n\nResponse Headers:\n- X-API-Version: 2.0\n- X-API-Deprecated: true\n- X-API-Sunset-Date: 2026-03-01\n- X-API-Migration-Guide: https://docs.techcorp.com/migration/v2\n\nDocumentation Requirements:\n- Changelog for each version\n- Migration guides with code examples\n- API version compatibility matrix\n- Deprecation timeline calendar\n\nDiscussion:\n- @sarah_dev: URL versioning is clearer than header-only approach\n- @maria_frontend: 6 months feels right for enterprise customers\n- @tech_lead_mike: Need to track which users are on old versions\n- @john_backend: I'll implement version routing middleware\n- @product_manager_lisa: This will improve customer trust\n\nStatus: Approved. Implementation tracked in ISSUE-2034. Target: Q4 2025 release.",
    "url": "https://internal-git.techcorp.com/rfcs/038",
    "type": "rfc",
    "status": "closed",
    "priority": "medium",
    "assignee": "sarah_dev",
    "created_date": "2025-09-03",
    "resolved_date": "2025-09-25",
    "labels": ["api", "architecture", "design", "rfc"],
    "related_pr": null
  },
  {
    "id": "ISSUE-1834",
    "title": "Add rate limiting per user endpoint",
    "text": "Description: Currently rate limiting is implemented globally at gateway level. Need per-user rate limiting to prevent abuse while allowing legitimate high-volume users.\n\nRequirements:\n- Implement sliding window rate limiter using Redis\n- Different limits for free tier (100 req/min) and premium (1000 req/min)\n- Return remaining quota in response headers\n- Graceful degradation if Redis is unavailable\n\nComments:\n- @john_backend: I'll implement using Redis sorted sets with ZREMRANGEBYSCORE\n- @sarah_dev: Need to coordinate with billing service for tier information\n- @maria_frontend: Should we show rate limit info in user dashboard?\n- @tech_lead_mike: Yes, add a usage widget showing current consumption\n\nImplementation completed in PR-543. Deployed to production 2025-09-12. Monitoring shows 300+ users hitting limits daily with appropriate 429 responses. No performance impact on API response times.",
    "url": "https://internal-git.techcorp.com/issues/1834",
    "type": "issue",
    "status": "closed",
    "priority": "medium",
    "assignee": "john_backend",
    "created_date": "2025-09-05",
    "resolved_date": "2025-09-12",
    "labels": ["feature", "api", "redis", "rate-limiting"],
    "related_pr": "PR-543"
  },
  {
    "id": "ISSUE-1756",
    "title": "Implement OAuth2 support for external API integrations",
    "text": "Description: Product team requesting OAuth2 authentication support for third-party integrations. Currently only supporting API key authentication which doesn't meet security requirements for enterprise customers.\n\nRequirements:\n- Support OAuth2 authorization code flow\n- Implement refresh token rotation\n- Add scopes for granular permission control\n- Support PKCE for mobile apps\n\nComments:\n- @sarah_dev: I can handle the backend implementation, estimated 3-4 days\n- @maria_frontend: Frontend changes needed for OAuth flow UI, will coordinate\n- @security_team_alice: Please ensure refresh tokens are stored encrypted in PostgreSQL\n- @john_backend: Let's use the authlib library for OAuth2, it's well maintained\n- @tech_lead_mike: Approved, targeting for Q4 release\n\nImplementation Notes:\n- Using PostgreSQL for token storage with encryption at rest\n- Redis for temporary authorization codes (5 minute TTL)\n- Integration tests covering all OAuth2 flows\n- Documentation for API consumers\n\nCurrent Status: Design phase complete, implementation starting next sprint.",
    "url": "https://internal-git.techcorp.com/issues/1756",
    "type": "issue",
    "status": "open",
    "priority": "high",
    "assignee": "sarah_dev",
    "created_date": "2025-09-08",
    "resolved_date": null,
    "labels": ["feature", "api", "security", "oauth"],
    "related_pr": null
  },
  {
    "id": "PR-543",
    "title": "Implement per-user rate limiting with Redis",
    "text": "Description: Implements sliding window rate limiter for ISSUE-1834 using Redis sorted sets.\n\nImplementation:\n- RateLimiter class using Redis ZSET with timestamp scores\n- Sliding window of 60 seconds\n- Automatic cleanup of old entries using ZREMRANGEBYSCORE\n- Fallback to in-memory limiter if Redis unavailable\n\nCode Structure:\n- New module: middleware/rate_limiter.py (180 lines)\n- Configuration in config/rate_limits.yaml\n- Integration in main.py request pipeline\n\nRate Limit Tiers:\n- Free tier: 100 requests/minute\n- Professional: 500 requests/minute  \n- Enterprise: 1000 requests/minute\n\nResponse Headers Added:\n- X-RateLimit-Limit: user's tier limit\n- X-RateLimit-Remaining: requests left in window\n- X-RateLimit-Reset: timestamp when limit resets\n\nTesting:\n- Unit tests with mocked Redis (coverage: 95%)\n- Load testing: 10k requests with mixed tiers, all limits enforced correctly\n- Latency impact: +0.8ms per request (acceptable)\n\nComments:\n- @sarah_dev: Clean implementation, like the fallback strategy\n- @tech_lead_mike: Approved, deploy to staging first\n- @alex_devops: Deployed to production 2025-09-12, monitoring looks good\n\nPost-Deployment: Running smoothly for 2 weeks, no issues reported.",
    "url": "https://internal-git.techcorp.com/pulls/543",
    "type": "pull_request",
    "status": "closed",
    "priority": "medium",
    "assignee": "john_backend",
    "created_date": "2025-09-10",
    "resolved_date": "2025-09-12",
    "labels": ["feature", "redis", "rate-limiting"],
    "related_pr": null
  },
  {
    "id": "RFC-045",
    "title": "Design Proposal: Microservices Migration Architecture",
    "text": "Abstract: This RFC proposes a phased approach to migrate our monolithic application to a microservices architecture over 18 months.\n\nCurrent State:\n- Single Django monolith (~250k lines of code)\n- PostgreSQL database with 50+ tables\n- Deployed as single unit, scaling limitations\n- Deployment takes 30 minutes, high risk\n\nProposed Architecture:\n1. API Gateway (Kong) - routing and authentication\n2. User Service - authentication and profile management\n3. Billing Service - subscriptions and payments\n4. Notification Service - emails, SMS, WebSocket\n5. Analytics Service - reporting and data warehouse\n6. Search Service - Elasticsearch integration\n\nCommunication:\n- Synchronous: REST APIs with circuit breakers\n- Asynchronous: RabbitMQ for events\n- Service mesh: Istio for observability\n\nData Strategy:\n- Each service owns its database\n- Event sourcing for data synchronization\n- Saga pattern for distributed transactions\n- Read replicas for cross-service queries\n\nMigration Phases:\nPhase 1 (Months 1-4): Extract notification service\nPhase 2 (Months 5-8): Extract billing service\nPhase 3 (Months 9-12): Extract user service\nPhase 4 (Months 13-18): Extract analytics and search\n\nInfrastructure Requirements:\n- Kubernetes cluster (3 nodes minimum per environment)\n- RabbitMQ cluster (3 nodes)\n- Service mesh (Istio)\n- Monitoring (Prometheus + Grafana)\n- Distributed tracing (Jaeger)\n\nEstimated Costs:\n- Infrastructure: +$5k/month\n- Engineering time: 2.5 FTE for 18 months\n- Risk mitigation: 3-month buffer\n\nDiscussion:\n- @tech_lead_mike: Strong proposal, phased approach reduces risk\n- @alex_devops: Infrastructure costs are manageable, need dedicated DevOps\n- @sarah_dev: Concerned about distributed transaction complexity\n- @john_backend: Event sourcing will help with debugging\n- @cto_robert: Approved in principle, need detailed Phase 1 plan\n\nStatus: Approved for Phase 1 implementation. Kickoff meeting scheduled 2025-10-01.",
    "url": "https://internal-git.techcorp.com/rfcs/045",
    "type": "rfc",
    "status": "open",
    "priority": "high",
    "assignee": "tech_lead_mike",
    "created_date": "2025-09-14",
    "resolved_date": null,
    "labels": ["architecture", "microservices", "design", "rfc"],
    "related_pr": null
  },
  {
    "id": "ISSUE-1847",
    "title": "API Gateway returning 429 errors during peak hours",
    "text": "Description: Users are experiencing 429 rate limit errors during peak hours (2-4 PM EST). The API gateway is rejecting requests even though we're within our configured limits.\n\nInvestigation:\n- @john_backend: Checked Redis cache, TTL is set correctly at 300s\n- @sarah_dev: Found the issue - middleware is not properly handling connection pooling\n- Root cause: Connection pool exhausted due to long-running queries in user service\n\nComments:\n- @maria_frontend: This is affecting the dashboard heavily, marking as critical\n- @john_backend: PR-567 ready with fix implementing exponential backoff\n- @alex_devops: Added monitoring alerts for connection pool utilization\n\nResolution: Deployed PR-567 to production on 2025-09-18. Monitoring shows 429 errors reduced by 95%. Added connection pool metrics to Grafana dashboard.",
    "url": "https://internal-git.techcorp.com/issues/1847",
    "type": "issue",
    "status": "closed",
    "priority": "critical",
    "assignee": "john_backend",
    "created_date": "2025-09-15",
    "resolved_date": "2025-09-18",
    "labels": ["bug", "api", "production", "performance"],
    "related_pr": "PR-567"
  },
  {
    "id": "PR-567",
    "title": "Fix connection pool exhaustion in API middleware",
    "text": "Description: Implements exponential backoff and proper connection pool management to resolve ISSUE-1847 (429 errors during peak hours).\n\nChanges:\n- Refactored middleware/connection_pool.py to use contextlib for proper cleanup\n- Increased pool size from 10 to 50 connections\n- Added exponential backoff with max retry of 3 attempts\n- Implemented connection health checks before reuse\n\nTechnical Details:\n- Using asyncpg connection pool with proper async context managers\n- Added metrics for pool utilization (current: 45%, max: 85%)\n- Timeout handling improved with graceful degradation\n\nTesting:\n- Unit tests for backoff logic (test_exponential_backoff.py)\n- Load testing with 500 concurrent users showed no 429 errors\n- Staging deployment ran for 48 hours without issues\n\nCode Review Comments:\n- @tech_lead_mike: LGTM, good use of async context managers\n- @sarah_dev: Consider adding alerts for pool utilization > 80%\n- @alex_devops: Approved for production deployment\n\nMetrics After Deployment:\n- 429 errors: 1200/hour â†’ 60/hour (95% reduction)\n- Average response time: 145ms â†’ 132ms\n- Connection pool utilization: stable at 45-55%",
    "url": "https://internal-git.techcorp.com/pulls/567",
    "type": "pull_request",
    "status": "closed",
    "priority": "critical",
    "assignee": "john_backend",
    "created_date": "2025-09-16",
    "resolved_date": "2025-09-18",
    "labels": ["bug-fix", "api", "performance"],
    "related_pr": null
  },
  {
    "id": "ISSUE-1889",
    "title": "SQL injection vulnerability in search endpoint",
    "text": "Description: Security audit identified SQL injection vulnerability in /api/v1/search endpoint. User input from query parameter is not properly sanitized before being used in raw SQL query.\n\nSeverity: HIGH - Immediate action required\n\nAffected Code:\n- File: services/search/query_builder.py\n- Line: 145-152\n- Issue: String concatenation used instead of parameterized queries\n\nInvestigation:\n- @security_team_alice: Confirmed exploitable with UNION-based injection\n- @sarah_dev: Checking all other endpoints for similar patterns\n- @john_backend: Found 3 more instances in legacy codebase\n\nRemediation:\n- Rewrite using SQLAlchemy ORM or parameterized queries\n- Add input validation and sanitization\n- Implement WAF rules as additional layer\n- Security regression tests\n\nComments:\n- @tech_lead_mike: Stop all other work, this is P0\n- @sarah_dev: PR-578 ready with fixes for all 4 vulnerable endpoints\n- @alex_devops: Deployed hotfix to production 2025-09-19 at 14:30 UTC\n- @security_team_alice: Verified fix, conducting full pentest next week\n\nResolution: All vulnerable endpoints patched. Added pre-commit hooks to catch raw SQL queries. Security training scheduled for team.",
    "url": "https://internal-git.techcorp.com/issues/1889",
    "type": "issue",
    "status": "closed",
    "priority": "critical",
    "assignee": "sarah_dev",
    "created_date": "2025-09-18",
    "resolved_date": "2025-09-19",
    "labels": ["security", "vulnerability", "bug", "sql"],
    "related_pr": "PR-578"
  },
  {
    "id": "PR-578",
    "title": "Security hotfix: Patch SQL injection vulnerabilities",
    "text": "Description: CRITICAL SECURITY FIX for ISSUE-1889. Patches SQL injection vulnerabilities in search and filter endpoints.\n\nVulnerabilities Fixed:\n1. services/search/query_builder.py - search endpoint\n2. services/filters/advanced_filter.py - filter endpoint  \n3. services/export/csv_export.py - export functionality\n4. services/admin/user_lookup.py - admin search\n\nChanges Applied:\n- Replaced all string concatenation with parameterized queries\n- Migrated to SQLAlchemy ORM where possible\n- Added input validation using Pydantic models\n- Implemented query whitelisting for column names\n- Added SQL injection detection in WAF rules\n\nSecurity Testing:\n- Attempted UNION-based injection: blocked âœ“\n- Attempted boolean-based injection: blocked âœ“\n- Attempted time-based injection: blocked âœ“\n- Tested with sqlmap: all attacks blocked âœ“\n\nCode Review:\n- @security_team_alice: Verified all fixes, running full pentest\n- @tech_lead_mike: APPROVED for immediate deployment\n- @john_backend: Reviewed query patterns, all look safe now\n\nDeployment:\n- Hotfix deployed 2025-09-19 at 14:30 UTC\n- No user-facing changes\n- API performance unchanged\n- Added security regression tests to CI pipeline\n\nFollow-up Actions:\n- Security training for team scheduled\n- Pre-commit hooks added to catch raw SQL\n- Code audit of entire codebase planned",
    "url": "https://internal-git.techcorp.com/pulls/578",
    "type": "pull_request",
    "status": "closed",
    "priority": "critical",
    "assignee": "sarah_dev",
    "created_date": "2025-09-19",
    "resolved_date": "2025-09-19",
    "labels": ["security", "hotfix", "sql"],
    "related_pr": null
  },
  {
    "id": "PR-598",
    "title": "Elasticsearch 8.x migration - Application code changes",
    "text": "Description: Updates application code for Elasticsearch 8.x compatibility as part of ISSUE-1712 migration.\n\nBreaking Changes Addressed:\n1. Removed mapping types (was using _doc type)\n2. Updated elasticsearch-py from 7.17.0 to 8.10.0\n3. Changed query DSL for better performance\n4. Updated index templates to new format\n\nCode Changes:\n- services/search/elasticsearch_client.py - major refactor\n- Updated all queries to use new Python client syntax\n- Removed deprecated query parameters\n- Added new security context for API keys\n\nIndex Template Updates:\n- Migrated from legacy to composable templates\n- Updated field mappings for text/keyword types\n- Added new runtime fields for computed values\n- Optimized for better search performance\n\nConfiguration Changes:\n- Added Elasticsearch API key authentication\n- Updated connection pool settings\n- Configured request compression\n- Added retry logic for transient failures\n\nTesting:\n- All 450 search integration tests passing\n- Performance testing shows 15% improvement in query speed\n- Backward compatibility maintained with feature flags\n- Staging cluster validated with production traffic replay\n\nComments:\n- @david_data: Composable templates much cleaner than legacy\n- @sarah_dev: Nice performance improvements in aggregation queries\n- @john_backend: API key auth is more secure than basic auth\n- @alex_devops: Staging migration complete, ready for production\n\nDeployment Plan:\n- Deploy code with feature flag (pointing to 7.x)\n- Switch traffic gradually to 8.x cluster\n- Monitor for 48 hours before decommissioning 7.x",
    "url": "https://internal-git.techcorp.com/pulls/598",
    "type": "pull_request",
    "status": "in_progress",
    "priority": "medium",
    "assignee": "david_data",
    "created_date": "2025-09-20",
    "resolved_date": null,
    "labels": ["infrastructure", "elasticsearch", "migration"],
    "related_pr": null
  },
  {
    "id": "ISSUE-1923",
    "title": "PostgreSQL query timeout in analytics service",
    "text": "Description: The analytics dashboard is timing out when users request reports for date ranges longer than 30 days. Query timeout set at 30s but queries are taking 45-60s.\n\nInvestigation:\n- @david_data: Analyzed query execution plan - missing index on transactions.created_at column\n- @sarah_dev: Confirmed table has 12M rows, full table scan happening\n- @john_backend: Tested with index in staging, query time reduced to 3.2s\n\nComments:\n- @maria_frontend: Users are complaining, this affects monthly/quarterly reports\n- @david_data: CREATE INDEX idx_transactions_created_at ON transactions(created_at, user_id)\n- @alex_devops: Index creation will take ~15 minutes in production, scheduling maintenance window\n\nStatus: PR-589 opened with migration. Waiting for approval from @tech_lead_mike before production deployment.",
    "url": "https://internal-git.techcorp.com/issues/1923",
    "type": "issue",
    "status": "in_progress",
    "priority": "high",
    "assignee": "david_data",
    "created_date": "2025-09-22",
    "resolved_date": null,
    "labels": ["bug", "database", "performance", "postgresql"],
    "related_pr": "PR-589"
  },
  {
    "id": "PR-589",
    "title": "Add database index for analytics query optimization",
    "text": "Description: Resolves ISSUE-1923 by adding composite index on transactions table to eliminate full table scans.\n\nDatabase Changes:\n- Added index: idx_transactions_created_at_user_id\n- Columns: (created_at DESC, user_id)\n- Index size: ~450MB\n- Creation time in production: estimated 12-15 minutes\n\nMigration Script:\nCREATE INDEX CONCURRENTLY idx_transactions_created_at_user_id \nON transactions(created_at DESC, user_id)\nWHERE deleted_at IS NULL;\n\nANALYZE transactions;\n\nPerformance Testing Results:\n- Before: 45-60s query time\n- After: 2.8-3.5s query time (94% improvement)\n- No impact on INSERT performance (tested with 10k inserts)\n- Disk usage increase: acceptable 450MB for 12M row table\n\nComments:\n- @david_data: Used CONCURRENTLY to avoid locking production table\n- @john_backend: Tested with full month query, works great\n- @tech_lead_mike: Approved, schedule for maintenance window\n- @alex_devops: Deployment scheduled for 2025-09-24 at 02:00 UTC\n\nStatus: Awaiting production deployment window.",
    "url": "https://internal-git.techcorp.com/pulls/589",
    "type": "pull_request",
    "status": "open",
    "priority": "high",
    "assignee": "david_data",
    "created_date": "2025-09-23",
    "resolved_date": null,
    "labels": ["database", "performance", "postgresql"],
    "related_pr": null
  },
  {
    "id": "ISSUE-1998",
    "title": "Memory leak in notification microservice",
    "text": "Description: Notification service consuming increasing memory over time, requiring restart every 48 hours. Heap usage grows from 512MB to 4GB before OOMKiller terminates the process.\n\nInvestigation:\n- @alex_devops: Monitoring shows steady memory growth, not correlated with traffic\n- @john_backend: Heap dump analysis reveals WebSocket connections not being properly closed\n- Root cause: Event listeners not being removed when WebSocket disconnects\n\nTechnical Details:\n- Node.js v20.5.1, using ws library for WebSocket connections\n- Found 3000+ orphaned event listeners after 24 hours runtime\n- Memory profile shows listeners retaining references to large user objects\n\nComments:\n- @sarah_dev: We should implement connection cleanup in the disconnect handler\n- @john_backend: Also need to add heartbeat mechanism to detect stale connections\n- @alex_devops: Current workaround: Auto-restart service every 24 hours via k8s\n- @tech_lead_mike: This is affecting 15k active WebSocket users, prioritize fix\n\nResolution: PR-612 implements proper cleanup with WeakMap for connection tracking. Testing in staging for 72 hours before production release.",
    "url": "https://internal-git.techcorp.com/issues/1998",
    "type": "issue",
    "status": "in_progress",
    "priority": "critical",
    "assignee": "john_backend",
    "created_date": "2025-09-28",
    "resolved_date": null,
    "labels": ["bug", "production", "memory-leak", "microservices"],
    "related_pr": "PR-612"
  },
  {
    "id": "PR-612",
    "title": "Fix memory leak in WebSocket notification service",
    "text": "Description: Resolves ISSUE-1998 memory leak caused by orphaned event listeners in WebSocket connections.\n\nRoot Cause Analysis:\n- Event listeners registered on connection but not removed on disconnect\n- Each listener retained reference to full user object (~8KB)\n- After 24 hours: 3000+ orphaned listeners = 24MB+ leaked memory\n- Compounded by other retained objects in closure scope\n\nImplementation:\n- Refactored connection manager to use WeakMap for listener tracking\n- Implemented explicit cleanup in disconnect handler\n- Added heartbeat mechanism (30s interval) to detect stale connections\n- Automatic connection timeout after 5 minutes of inactivity\n\nCode Changes:\n- services/notifications/websocket_manager.js - 250 lines refactored\n- Added cleanup middleware in disconnect pipeline\n- Implemented connection pool monitoring\n- Memory profiling instrumentation added\n\nTesting:\n- Load test: 5000 concurrent WebSocket connections for 72 hours\n- Memory usage: stable at 512MB (previously grew to 4GB)\n- No connection drops or data loss\n- Heap snapshots show proper cleanup\n\nComments:\n- @john_backend: Used WeakMap to prevent memory retention\n- @alex_devops: Running in staging, memory is flat, looking good!\n- @tech_lead_mike: Excellent fix, approve for production after 72h staging test\n- @sarah_dev: Should we add memory usage alerts? \n- @alex_devops: Added CloudWatch alert for >2GB usage\n\nStatus: In staging testing, pending 72-hour validation before production.",
    "url": "https://internal-git.techcorp.com/pulls/612",
    "type": "pull_request",
    "status": "in_progress",
    "priority": "critical",
    "assignee": "john_backend",
    "created_date": "2025-09-29",
    "resolved_date": null,
    "labels": ["bug-fix", "memory-leak", "websocket"],
    "related_pr": null
  }
]
