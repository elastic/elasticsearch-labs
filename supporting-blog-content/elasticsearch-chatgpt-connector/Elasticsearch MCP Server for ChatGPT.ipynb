{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvOHZz8TX_cp"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Elasticsearch MCP Server for ChatGPT\n",
        "This notebook deploys an MCP (Model Context Protocol) server that connects ChatGPT to Elasticsearch, enabling natural language queries over internal GitHub issues and pull requests.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuAQtd-BYfTZ"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDRrpVfMNZpA",
        "outputId": "8b8a3d59-92d9-4763-9ca0-30fd46763c94"
      },
      "outputs": [],
      "source": [
        "!pip install fastmcp elasticsearch pyngrok pandas -q\n",
        "print(\"Dependencies installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So0cgu4cYy4e"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVWlHusQpy9n",
        "outputId": "ea0eb9a3-1524-4016-e01f-1b2a510f5eb2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import threading\n",
        "import time\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Any\n",
        "from getpass import getpass\n",
        "from fastmcp import FastMCP\n",
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch.helpers import bulk\n",
        "from pyngrok import ngrok\n",
        "from pyngrok.conf import PyngrokConfig\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycdj_n8DY8p8"
      },
      "source": [
        "## Setup Configuration\n",
        "\n",
        "**Important**: Set these environment variables before running this notebook:\n",
        "- `ELASTICSEARCH_URL` - Your Elasticsearch cluster URL\n",
        "- `ELASTICSEARCH_API_KEY` - API key with read access to your index\n",
        "- `NGROK_TOKEN` - Your ngrok auth token from [here](https://dashboard.ngrok.com/).\n",
        "\n",
        "**How to set environment variables:**\n",
        "- In Jupyter/VS Code: Use a `.env` file or set them in your terminal before starting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"ELASTICSEARCH_URL\"] = os.environ.get(\"ELASTICSEARCH_URL\") or getpass(\"Enter your Elasticsearch URL: \")\n",
        "os.environ[\"ELASTICSEARCH_API_KEY\"] = os.environ.get(\"ELASTICSEARCH_API_KEY\") or getpass(\"Enter your Elasticsearch API key: \")\n",
        "os.environ[\"NGROK_TOKEN\"] = os.environ.get(\"NGROK_TOKEN\") or getpass(\"Enter your Ngrok Token: \")\n",
        "os.environ[\"ELASTICSEARCH_INDEX\"] = os.environ.get(\"ELASTICSEARCH_INDEX\") or getpass(\"Enter your Elasticsearch Index name (default: github_internal): \") or \"github_internal\"\n",
        "\n",
        "ELASTICSEARCH_URL = os.environ[\"ELASTICSEARCH_URL\"]\n",
        "ELASTICSEARCH_API_KEY = os.environ[\"ELASTICSEARCH_API_KEY\"]\n",
        "NGROK_TOKEN = os.environ[\"NGROK_TOKEN\"]\n",
        "INDEX_NAME = os.environ[\"ELASTICSEARCH_INDEX\"]\n",
        "\n",
        "print(\"Configuration loaded successfully\")\n",
        "print(f\"Index name: {INDEX_NAME}\")\n",
        "print(f\"Elasticsearch URL: {ELASTICSEARCH_URL[:30]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5nVMK5EhdCL"
      },
      "source": [
        "## Initialize Elasticsearch Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4tv4KLWhe8X",
        "outputId": "aa70e0ef-f46e-4df6-f188-c024ef0e4aed"
      },
      "outputs": [],
      "source": [
        "es_client = Elasticsearch(\n",
        "    ELASTICSEARCH_URL,\n",
        "    api_key=ELASTICSEARCH_API_KEY\n",
        ")\n",
        "\n",
        "if es_client.ping():\n",
        "    print(\"Elasticsearch connection successful\")\n",
        "    cluster_info = es_client.info()\n",
        "    print(f\"Cluster: {cluster_info['cluster_name']}\")\n",
        "    print(f\"Version: {cluster_info['version']['number']}\")\n",
        "else:\n",
        "    print(\"ERROR: Could not connect to Elasticsearch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYfKl1uhZyLo"
      },
      "source": [
        "## Create Index with Mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqRm1fRqZ2E-",
        "outputId": "a1e4b28f-8b19-4d59-ad02-2d7a4bfdefe0"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    es_client.indices.create(\n",
        "        index=INDEX_NAME,\n",
        "        body={\n",
        "            \"mappings\": {\n",
        "                \"properties\": {\n",
        "                    \"id\": {\"type\": \"keyword\"},\n",
        "                    \"title\": {\"type\": \"text\"},\n",
        "                    \"text\": {\"type\": \"text\"},\n",
        "                    \"text_semantic\": {\n",
        "                        \"type\": \"semantic_text\",\n",
        "                        \"inference_id\": \".elser-2-elasticsearch\"\n",
        "                    },\n",
        "                    \"url\": {\"type\": \"keyword\"},\n",
        "                    \"type\": {\"type\": \"keyword\"},\n",
        "                    \"status\": {\"type\": \"keyword\"},\n",
        "                    \"priority\": {\"type\": \"keyword\"},\n",
        "                    \"assignee\": {\"type\": \"keyword\"},\n",
        "                    \"created_date\": {\"type\": \"date\", \"format\": \"iso8601\"},\n",
        "                    \"resolved_date\": {\"type\": \"date\", \"format\": \"iso8601\"},\n",
        "                    \"labels\": {\"type\": \"keyword\"},\n",
        "                    \"related_pr\": {\"type\": \"keyword\"}\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    )\n",
        "    print(f\"Index '{INDEX_NAME}' created successfully\")\n",
        "except Exception as e:\n",
        "    if 'resource_already_exists_exception' in str(e):\n",
        "        print(f\"Index '{INDEX_NAME}' already exists\")\n",
        "    else:\n",
        "        print(f\"Error creating index: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFw3zTwpcYJq"
      },
      "source": [
        "## Load Sample Dataset\n",
        "\n",
        "**Dataset**: 15 documents including issues, pull requests, and RFCs with realistic content, comments, and relationships.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = 'github_internal_dataset.json'\n",
        "df = pd.read_json(file_path)\n",
        "\n",
        "documents = df.to_dict('records')\n",
        "print(f\"Loaded {len(documents)} documents from dataset\")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80BHi4HgdSxh"
      },
      "source": [
        "## Ingest Documents to Elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1JgCgwldWhN",
        "outputId": "1cae2312-5508-4757-a3c8-c2a2870ba129"
      },
      "outputs": [],
      "source": [
        "def generate_actions():\n",
        "    for doc in documents:\n",
        "        doc['text_semantic'] = doc['text']\n",
        "        yield {\n",
        "            '_index': INDEX_NAME,\n",
        "            '_source': doc\n",
        "        }\n",
        "\n",
        "try:\n",
        "    success, errors = bulk(es_client, generate_actions())\n",
        "    print(f\"Successfully indexed {success} documents\")\n",
        "\n",
        "    if errors:\n",
        "        print(f\"Errors during indexing: {errors}\")\n",
        "\n",
        "    print(\"Waiting 15 seconds for ELSER to process documents...\")\n",
        "    time.sleep(15)\n",
        "\n",
        "    count = es_client.count(index=INDEX_NAME)['count']\n",
        "    print(f\"Total documents in index: {count}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during bulk indexing: {str(e)}\")\n",
        "    print(\"If you see timeout errors, wait a few seconds and try again\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTg5ePAbdbCW"
      },
      "source": [
        "## Define MCP Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aLcJzLxdeLS",
        "outputId": "3c29e137-1c9f-43ee-bb33-c18945c34680"
      },
      "outputs": [],
      "source": [
        "server_instructions = \"\"\"\n",
        "This MCP server provides access to TechCorp's internal GitHub issues and pull requests.\n",
        "Use search to find relevant issues/PRs, then fetch to get complete details.\n",
        "\"\"\"\n",
        "\n",
        "def create_server():\n",
        "    mcp = FastMCP(\n",
        "        name=\"Elasticsearch GitHub Issues MCP\",\n",
        "        instructions=server_instructions\n",
        "    )\n",
        "\n",
        "    @mcp.tool()\n",
        "    async def search(query: str) -> Dict[str, List[Dict[str, Any]]]:\n",
        "        \"\"\"\n",
        "        Search for internal issues and PRs using hybrid search.\n",
        "        Returns list with id, title, and url.\n",
        "        \"\"\"\n",
        "        if not query or not query.strip():\n",
        "            return {\"results\": []}\n",
        "\n",
        "        logger.info(f\"Searching for: '{query}'\")\n",
        "\n",
        "        try:\n",
        "            response = es_client.search(\n",
        "                index=INDEX_NAME,\n",
        "                size=10,\n",
        "                source=[\"id\", \"title\", \"url\", \"type\", \"priority\"],\n",
        "                retriever={\n",
        "                    \"rrf\": {\n",
        "                        \"retrievers\": [\n",
        "                            {\n",
        "                                \"standard\": {\n",
        "                                    \"query\": {\n",
        "                                        \"semantic\": {\n",
        "                                            \"field\": \"text_semantic\",\n",
        "                                            \"query\": query\n",
        "                                        }\n",
        "                                    }\n",
        "                                }\n",
        "                            },\n",
        "                            {\n",
        "                                \"standard\": {\n",
        "                                    \"query\": {\n",
        "                                        \"multi_match\": {\n",
        "                                            \"query\": query,\n",
        "                                            \"fields\": [\n",
        "                                                \"title^3\",\n",
        "                                                \"text^2\",\n",
        "                                                \"assignee^2\",\n",
        "                                                \"type\",\n",
        "                                                \"labels\",\n",
        "                                                \"priority\"\n",
        "                                            ],\n",
        "                                            \"type\": \"best_fields\",\n",
        "                                            \"fuzziness\": \"AUTO\"\n",
        "                                        }\n",
        "                                    }\n",
        "                                }\n",
        "                            }\n",
        "                        ],\n",
        "                        \"rank_window_size\": 50,\n",
        "                        \"rank_constant\": 60\n",
        "                    }\n",
        "                }\n",
        "            )\n",
        "\n",
        "            results = []\n",
        "            if response and 'hits' in response:\n",
        "                for hit in response['hits']['hits']:\n",
        "                    source = hit['_source']\n",
        "                    results.append({\n",
        "                        \"id\": source.get('id', hit['_id']),\n",
        "                        \"title\": source.get('title', 'Unknown'),\n",
        "                        \"url\": source.get('url', '')\n",
        "                    })\n",
        "\n",
        "            logger.info(f\"Found {len(results)} results\")\n",
        "            return {\"results\": results}\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Search error: {e}\")\n",
        "            raise ValueError(f\"Search failed: {str(e)}\")\n",
        "\n",
        "    @mcp.tool()\n",
        "    async def fetch(id: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Retrieve complete issue/PR details by ID.\n",
        "        Returns id, title, text, url, and metadata.\n",
        "        \"\"\"\n",
        "        if not id:\n",
        "            raise ValueError(\"ID is required\")\n",
        "\n",
        "        logger.info(f\"Fetching: {id}\")\n",
        "\n",
        "        try:\n",
        "            response = es_client.search(\n",
        "                index=INDEX_NAME,\n",
        "                body={\n",
        "                    \"query\": {\n",
        "                        \"term\": {\n",
        "                            \"id\": id\n",
        "                        }\n",
        "                    },\n",
        "                    \"size\": 1\n",
        "                }\n",
        "            )\n",
        "\n",
        "            if not response or not response['hits']['hits']:\n",
        "                raise ValueError(f\"Document with id '{id}' not found\")\n",
        "\n",
        "            hit = response['hits']['hits'][0]\n",
        "            source = hit['_source']\n",
        "\n",
        "            result = {\n",
        "                \"id\": source.get('id', id),\n",
        "                \"title\": source.get('title', 'Unknown'),\n",
        "                \"text\": source.get('text', ''),\n",
        "                \"url\": source.get('url', ''),\n",
        "                \"type\": source.get('type', ''),\n",
        "                \"status\": source.get('status', ''),\n",
        "                \"priority\": source.get('priority', ''),\n",
        "                \"assignee\": source.get('assignee', ''),\n",
        "                \"created_date\": source.get('created_date', ''),\n",
        "                \"resolved_date\": source.get('resolved_date', ''),\n",
        "                \"labels\": source.get('labels', ''),\n",
        "                \"related_pr\": source.get('related_pr', '')\n",
        "            }\n",
        "\n",
        "            logger.info(f\"Fetched: {result['title']}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Fetch error: {e}\")\n",
        "            raise ValueError(f\"Failed to fetch '{id}': {str(e)}\")\n",
        "\n",
        "    return mcp\n",
        "\n",
        "print(\"MCP server defined successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aTU4xeedpHc"
      },
      "source": [
        "## Start Ngrok Tunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN-wlTOGdtIs",
        "outputId": "c78552d6-914d-4327-943f-6430d4f12569"
      },
      "outputs": [],
      "source": [
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "pyngrok_config = PyngrokConfig(region=\"us\")\n",
        "public_url = ngrok.connect(\n",
        "    8000,\n",
        "    \"http\",\n",
        "    pyngrok_config=pyngrok_config,\n",
        "    bind_tls=True\n",
        ")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MCP SERVER IS READY!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nPublic URL (use in ChatGPT): {public_url}/sse\")\n",
        "print(\"\\nIMPORTANT: Copy the URL above (including /sse at the end)\")\n",
        "print(\"\\nTo connect in ChatGPT:\")\n",
        "print(\"1. Go to Settings > Connectors\")\n",
        "print(\"2. Click 'Create' or 'Add Custom Connector'\")\n",
        "print(\"3. Paste the URL above\")\n",
        "print(\"4. Save and start using!\")\n",
        "print(\"\\nKeep this notebook running while using the connector\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFfSlDVAdxe1"
      },
      "source": [
        "## Run MCP Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "okQYfcJfdzp-",
        "outputId": "d226ff48-41fc-4b5b-b63d-f651a20d23d5"
      },
      "outputs": [],
      "source": [
        "server = create_server()\n",
        "\n",
        "print(\"Starting MCP server...\")\n",
        "print(\"Server is running. To stop: Runtime > Interrupt execution\")\n",
        "print()\n",
        "\n",
        "def run_server():\n",
        "    server.run(transport=\"sse\", host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "print(\"Server started successfully!\")\n",
        "print(\"Your ngrok URL is ready to use in ChatGPT\")\n",
        "print(\"Keep this cell running...\")\n",
        "print()\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nServer stopped\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNzxwv__hy8D"
      },
      "source": [
        "## Cleanup (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7C6sin_gh2Be"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    result = es_client.indices.delete(index=INDEX_NAME, ignore=[400, 404])\n",
        "    if result.get('acknowledged', False):\n",
        "        print(f\"Index '{INDEX_NAME}' deleted successfully\")\n",
        "    else:\n",
        "        print(f\"Error deleting index: {result}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
