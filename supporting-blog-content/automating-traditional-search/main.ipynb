{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Faceting and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import traceback\n",
    "import uuid\n",
    "import os\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import string\n",
    "\n",
    "import pickle\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AzureOpenAIClient:\n",
    "    def __init__(self):\n",
    "        self.client = AzureOpenAI(\n",
    "            api_key=os.environ.get(\"AZURE_OPENAI_KEY_1\"),\n",
    "            api_version=\"2024-06-01\",\n",
    "            azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        )\n",
    "\n",
    "    def generate_streaming_response(self, prompt, model=\"gpt-4o\", system_prompt=\"\"):\n",
    "        response_text = \"\"\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            message_placeholder = st.empty()\n",
    "            for chunk in self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                stream=True,\n",
    "                max_tokens=4096\n",
    "            ):\n",
    "                if len(chunk.choices) > 0:\n",
    "                    if chunk.choices[0].delta.content is not None:\n",
    "                        response_text += chunk.choices[0].delta.content\n",
    "                        message_placeholder.markdown(response_text + \"â–Œ\")\n",
    "        return response_text\n",
    "\n",
    "    def generate_non_streaming_response(self, prompt, model=\"gpt-4o\", system_prompt=\"\"):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=4096\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "LLM = AzureOpenAIClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_random_email():\n",
    "    # Generate a random username length between 5 and 12 characters\n",
    "    username_length = random.randint(5, 12)\n",
    "    \n",
    "    # Generate a random username using lowercase letters and digits\n",
    "    username = ''.join(random.choices(string.ascii_lowercase + string.digits, k=username_length))\n",
    "    \n",
    "    # List of common email domains\n",
    "    domains = ['gmail.com', 'yahoo.com', 'hotmail.com', 'outlook.com', 'icloud.com']\n",
    "    \n",
    "    # Choose a random domain\n",
    "    domain = random.choice(domains)\n",
    "    \n",
    "    # Construct and return the email\n",
    "    return f\"{username}@{domain}\"\n",
    "\n",
    "\n",
    "def generate_chinese_name():\n",
    "    chinese_surnames = [\n",
    "        \"Tan\", \"Lim\", \"Lee\", \"Ng\", \"Ong\", \"Wong\", \"Goh\", \"Chua\", \"Koh\", \"Teo\", \"Chan\", \"Yeo\", \"Ang\", \"Chong\", \"Leong\", \"Foo\", \"Sim\", \"Tay\", \"Ho\", \"Low\",\n",
    "        \"Chen\", \"Lin\", \"Huang\", \"Zhang\", \"Li\", \"Wang\", \"Liu\", \"Wu\", \"Yang\", \"Zhou\", \"Xu\", \"Sun\", \"Ma\", \"Zhu\", \"Hu\", \"Guo\", \"He\", \"Gao\", \"Lin\", \"Luo\",\n",
    "        \"Zheng\", \"Liang\", \"Xie\", \"Song\", \"Tang\", \"Xu\", \"Han\", \"Feng\", \"Deng\", \"Xiao\", \"Cheng\", \"Cao\", \"Peng\", \"Zeng\", \"Xue\", \"Lu\", \"Su\", \"Pan\", \"Jiang\", \"Bai\",\n",
    "        \"Du\", \"Yin\", \"Mei\", \"Fang\", \"Fu\", \"Yuan\", \"Cai\", \"Jia\", \"Gu\", \"Xiong\", \"Hao\", \"Shao\", \"Meng\", \"Long\", \"Wei\", \"Wan\", \"Duan\", \"Qiu\", \"Jiang\", \"Qin\",\n",
    "        \"Chu\", \"Yu\", \"Shen\", \"Qi\", \"Cui\", \"Ren\", \"Tian\", \"Xia\", \"Shi\", \"Hou\", \"Yan\", \"Jin\", \"Kong\", \"Wei\", \"Xiang\", \"Yao\", \"Yan\", \"Sheng\", \"Zu\", \"Qian\"\n",
    "    ]\n",
    "\n",
    "    chinese_given_names = [\n",
    "        \"Wei\", \"Hui\", \"Xin\", \"Yi\", \"Ying\", \"Jie\", \"Ling\", \"Zhi\", \"Qiang\", \"Mei\", \"Jun\", \"Xiang\", \"Hao\", \"Chen\", \"Ming\", \"Feng\", \"Yang\", \"Cheng\", \"Yong\", \"Tian\",\n",
    "        \"Jing\", \"Yan\", \"Fei\", \"Yu\", \"Xiuying\", \"Guiying\", \"Chunmei\", \"Xiaohong\", \"Xiulan\", \"Guilan\", \"Huifang\", \"Xiuzhen\", \"Yumei\", \"Xiumei\", \"Guirong\", \"Shulan\", \"Guizhi\", \"Xiuyun\", \"Huiying\", \"Jinlan\",\n",
    "        \"Qing\", \"Xuan\", \"Zhen\", \"Rui\", \"Kai\", \"Sheng\", \"Hong\", \"Xiong\", \"Lei\", \"Hua\", \"Bin\", \"Heng\", \"Xiaowei\", \"Xiaojun\", \"Xiaofeng\", \"Xiaogang\", \"Xiaoming\", \"Xiaohua\", \"Xiaohui\", \"Xiaolin\",\n",
    "        \"An\", \"Bao\", \"Bo\", \"Chang\", \"Chao\", \"Da\", \"Dong\", \"En\", \"Gang\", \"Guo\", \"Hai\", \"Han\", \"Jian\", \"Jiao\", \"Jin\", \"Kang\", \"Lang\", \"Li\", \"Liang\", \"Miao\",\n",
    "        \"Nan\", \"Peng\", \"Ping\", \"Qi\", \"Qian\", \"Rong\", \"Ru\", \"Shan\", \"Shu\", \"Tai\", \"Tao\", \"Wen\", \"Wu\", \"Xia\", \"Xian\", \"Xiao\", \"Xue\", \"Yao\", \"Yi\", \"Yin\",\n",
    "        \"Yu\", \"Yuan\", \"Yun\", \"Zhan\", \"Zhe\", \"Zhong\", \"Zi\", \"Ai\", \"Bi\", \"Cai\", \"Can\", \"Ce\", \"Cui\", \"Di\", \"E\", \"Fu\", \"Gai\", \"Gan\", \"Huan\", \"Jia\",\n",
    "        \"Jiu\", \"Ju\", \"Kui\", \"Lan\", \"Lian\", \"Meng\", \"Nian\", \"Ning\", \"Nu\", \"Pin\", \"Qiu\", \"Quan\", \"Sha\", \"Shi\", \"Si\", \"Song\", \"Su\", \"Ti\", \"Tong\", \"Wai\",\n",
    "        \"Xi\", \"Xiu\", \"Xu\", \"Ya\", \"Yan\", \"Ye\", \"Ying\", \"You\", \"Zai\", \"Ze\", \"Zeng\", \"Zhi\", \"Zhuo\", \"Zi\", \"Zong\", \"Zou\"\n",
    "    ]\n",
    "    \n",
    "    surname = random.choice(chinese_surnames)\n",
    "    given_name = random.choice(chinese_given_names)\n",
    "    \n",
    "    # Sometimes add a second character to the given name\n",
    "    if random.random() < 0.5:  # 50% chance for a two-character given name\n",
    "        given_name += ' '+random.choice(chinese_given_names)\n",
    "    \n",
    "    return f\"{surname} {given_name}\"\n",
    "\n",
    "\n",
    "def generate_malay_name():\n",
    "    malay_given_names = [\n",
    "        \"Abdullah\", \"Abdul Rahman\", \"Abdul Rahim\", \"Abdul Aziz\", \"Abdul Kadir\", \"Abdul Latif\", \"Abdul Malik\", \"Abdul Razak\", \"Abu Bakar\", \"Adam\", \"Adil\", \"Adnan\", \"Ahmad\", \"Aiman\", \"Aizat\", \"Akmal\", \"Ali\", \"Amin\", \"Amir\", \"Ammar\",\n",
    "        \"Anuar\", \"Arif\", \"Ashraf\", \"Asraf\", \"Azhar\", \"Aziz\", \"Azlan\", \"Azman\", \"Azmi\", \"Badrul\", \"Baharudin\", \"Bakri\", \"Borhan\", \"Burhanuddin\", \"Che\", \"Danial\", \"Daud\", \"Dzulkifli\", \"Edzham\", \"Fadil\", \"Fahmi\", \"Faisal\", \"Faizal\", \"Farid\", \"Faris\",\n",
    "        \"Fauzi\", \"Fuad\", \"Ghazali\", \"Hadi\", \"Hafiz\", \"Hakim\", \"Halim\", \"Hamid\", \"Hamzah\", \"Hanafi\", \"Haris\", \"Harith\", \"Haron\", \"Hasan\", \"Hashim\", \"Hassan\", \"Haziq\", \"Helmi\", \"Hisham\", \"Husain\", \"Hussein\", \"Ibrahim\", \"Idris\", \"Ihsan\",\n",
    "        \"Imran\", \"Irfan\", \"Isa\", \"Ismail\", \"Izwan\", \"Jafar\", \"Jamal\", \"Jamil\", \"Johari\", \"Kamal\", \"Kamarul\", \"Kamaruzaman\", \"Khairil\", \"Khairuddin\", \"Khalid\", \"Lokman\", \"Lutfi\", \"Mahathir\", \"Mahmud\", \"Majid\", \"Malik\", \"Mansor\", \"Mas\", \"Mat\", \"Megat\",\n",
    "        \"Mizan\", \"Mohamad\", \"Mohamed\", \"Mohammad\", \"Mohammed\", \"Mohd\", \"Muhamad\", \"Muhammad\", \"Muhsin\", \"Mukhriz\", \"Munir\", \"Mustafa\", \"Muthu\", \"Nasir\", \"Nasrudin\", \"Nazri\", \"Nik\", \"Nizam\", \"Noor\", \"Nor\", \"Nordin\", \"Omar\", \"Osman\", \"Othman\",\n",
    "        \"Radzi\", \"Rafiq\", \"Rahimi\", \"Rahim\", \"Rahman\", \"Rashid\", \"Razak\", \"Razali\", \"Redza\", \"Redzuan\", \"Riduan\", \"Rizal\", \"Roslan\", \"Ruslan\", \"Saad\", \"Sabri\", \"Saffuan\", \"Saiful\", \"Saleh\", \"Salleh\", \"Samad\", \"Shafiq\", \"Shah\", \"Shahrul\", \"Shamsudin\",\n",
    "        \"Shamsul\", \"Sharif\", \"Sulaiman\", \"Syed\", \"Syukri\", \"Tarmizi\", \"Taufiq\", \"Tengku\", \"Umar\", \"Wan\", \"Yusof\", \"Yusoff\", \"Yusri\", \"Zafran\", \"Zainal\", \"Zakaria\", \"Zaki\", \"Zamri\", \"Zikri\", \"Zulkifli\",\n",
    "        \"Adibah\", \"Adila\", \"Adina\", \"Afiqah\", \"Aida\", \"Aishah\", \"Aisyah\", \"Alya\", \"Amalina\", \"Amelia\", \"Amira\", \"Amirah\", \"Aminah\", \"Anisah\", \"Aqilah\", \"Arissa\", \"Asma\", \"Asmah\", \"Atiqah\", \"Azizah\",\n",
    "        \"Azlina\", \"Azwa\", \"Balqis\", \"Dalila\", \"Dayang\", \"Eliana\", \"Emilia\", \"Farah\", \"Farhana\", \"Farhanah\", \"Fariha\", \"Faridah\", \"Farihah\", \"Fasihah\", \"Fatimah\", \"Fatin\", \"Fazlin\", \"Hafizah\", \"Halimatun\", \"Hamidah\",\n",
    "        \"Hanisah\", \"Hasmah\", \"Hasnah\", \"Haziqah\", \"Hazwani\", \"Hidayah\", \"Humaira\", \"Izzati\", \"Jamilah\", \"Khadijah\", \"Khairunnisa\", \"Laila\", \"Latifah\", \"Lina\", \"Madiha\", \"Maisarah\", \"Mariam\", \"Maryam\", \"Mas\", \"Mastura\",\n",
    "        \"Mawar\", \"Nabila\", \"Nabilah\", \"Nadiah\", \"Nadirah\", \"Nafeesa\", \"Najwa\", \"Nasyitah\", \"Natasha\", \"Nazifah\", \"Nazirah\", \"Nik\", \"Noor\", \"Noorul\", \"Nor\", \"Nora\", \"Noraini\", \"Norashikin\", \"Norazlina\", \"Norhayati\",\n",
    "        \"Noriah\", \"Norizan\", \"Norlia\", \"Normah\", \"Norziana\", \"Nur\", \"Nurain\", \"Nuraina\", \"Nuraliya\", \"Nuramira\", \"Nurassyifa\", \"Nurdiana\", \"Nurfadilah\", \"Nurfaizah\", \"Nurfarahana\", \"Nurhafizah\", \"Nurhaliza\", \"Nurhayati\", \"Nurhidayah\", \"Nurin\",\n",
    "        \"Nurliyana\", \"Nurmala\", \"Nurshahira\", \"Nursyafiqah\", \"Nursyahirah\", \"Nurul\", \"Puteri\", \"Qistina\", \"Rabiatul\", \"Rabiatuladawiyah\", \"Radin\", \"Rahmah\", \"Raja\", \"Rashidah\", \"Rosmah\", \"Rossita\", \"Rozita\", \"Safiah\", \"Safinah\", \"Safiyyah\",\n",
    "        \"Saleha\", \"Salina\", \"Salma\", \"Saodah\", \"Sarah\", \"Shafiqah\", \"Sharifah\", \"Siti\", \"Sofia\", \"Sofiah\", \"Sofiyah\", \"Sumaiyah\", \"Suraya\", \"Syafiqah\", \"Syahirah\", \"Syairah\", \"Syakila\", \"Syamimi\", \"Syaza\", \"Syazwani\",\n",
    "        \"Tengku\", \"Ummi\", \"Umi\", \"Wan\", \"Yasmin\", \"Yusrina\", \"Zainab\", \"Zainal\", \"Zainun\", \"Zakiah\", \"Zaleha\", \"Zalina\", \"Zanariah\", \"Zarina\", \"Zulaika\", \"Zulaikha\", \"Zulaikhah\", \"Zulfah\"\n",
    "    ]\n",
    "\n",
    "    malay_surnames = [\"bin\", \"binti\"]\n",
    "    \n",
    "    first_name = random.choice(malay_given_names)\n",
    "    middle_name = random.choice(malay_given_names)\n",
    "    surname = random.choice(malay_surnames)\n",
    "    \n",
    "    # Sometimes add a title or honorific\n",
    "    titles = [\"Haji\", \"Hajjah\", \"Tan Sri\", \"Puan Sri\", \"Datuk\", \"Datin\", \"Tun\", \"Toh Puan\"]\n",
    "    if random.random() < 0.1:  # 10% chance to add a title\n",
    "        title = random.choice(titles)\n",
    "        return f\"{title} {first_name} {surname} {middle_name}\"\n",
    "    \n",
    "    return f\"{first_name} {surname} {middle_name}\"\n",
    "\n",
    "def generate_indian_name():\n",
    "    indian_given_names = [\n",
    "        \"Aadhav\", \"Aadit\", \"Aaditya\", \"Aakash\", \"Aalam\", \"Aalok\", \"Aamir\", \"Aanjaneya\", \"Aarav\", \"Aarnav\", \"Aarush\", \"Aayush\", \"Abha\", \"Abhai\", \"Abhay\", \"Abhijat\", \"Abhijeet\", \"Abhimanyu\", \"Abhinav\", \"Abhishek\",\n",
    "        \"Abishek\", \"Aditi\", \"Aditya\", \"Advik\", \"Agastya\", \"Agni\", \"Aishwarya\", \"Ajay\", \"Ajeet\", \"Akash\", \"Akhil\", \"Akshay\", \"Akshita\", \"Alok\", \"Amal\", \"Aman\", \"Amar\", \"Amarnath\", \"Amey\", \"Amish\",\n",
    "        \"Amit\", \"Amita\", \"Amitabh\", \"Amolak\", \"Amrita\", \"Anand\", \"Anandi\", \"Anamika\", \"Ananth\", \"Ananya\", \"Anarya\", \"Anay\", \"Anaya\", \"Aniket\", \"Anil\", \"Aniruddha\", \"Anish\", \"Anit\", \"Anita\", \"Anjali\",\n",
    "        \"Anjana\", \"Anjan\", \"Anjney\", \"Ankit\", \"Ankita\", \"Ankur\", \"Anmol\", \"Ansh\", \"Anshika\", \"Anshul\", \"Anuj\", \"Anupam\", \"Anushka\", \"Anurag\", \"Aparna\", \"Apoorva\", \"Arav\", \"Arjun\", \"Arka\", \"Arnav\",\n",
    "        \"Arohi\", \"Arpit\", \"Artha\", \"Arun\", \"Aruna\", \"Arundhati\", \"Arushi\", \"Arya\", \"Asha\", \"Ashok\", \"Ashwin\", \"Asim\", \"Astha\", \"Atharv\", \"Ati\", \"Atiksh\", \"Atishay\", \"Atul\", \"Aum\", \"Avani\",\n",
    "        \"Avantika\", \"Avichal\", \"Avinash\", \"Ayaan\", \"Ayush\", \"Ayushi\", \"Bala\", \"Balaji\", \"Bharat\", \"Bharath\", \"Bhargav\", \"Bhargavi\", \"Bhaskar\", \"Bhavana\", \"Bhavesh\", \"Bhavya\", \"Bhoomi\", \"Bijay\", \"Bina\", \"Bindu\",\n",
    "        \"Chandan\", \"Chandra\", \"Chandran\", \"Charu\", \"Chetan\", \"Chetana\", \"Chirag\", \"Chitrangada\", \"Darshan\", \"Daya\", \"Deepa\", \"Deepak\", \"Deepika\", \"Dev\", \"Deva\", \"Devdan\", \"Devendra\", \"Devi\", \"Devika\", \"Dhairya\",\n",
    "        \"Dhananjay\", \"Dharma\", \"Dharmendra\", \"Dhruv\", \"Dilip\", \"Disha\", \"Divya\", \"Diya\", \"Durga\", \"Esha\", \"Ekta\", \"Gauri\", \"Gautam\", \"Gayathri\", \"Geeta\", \"Girish\", \"Gita\", \"Gitanjali\", \"Gopal\", \"Gopinath\",\n",
    "        \"Govind\", \"Gowri\", \"Gulshan\", \"Gunjan\", \"Guru\", \"Harsh\", \"Harsha\", \"Harshad\", \"Harshita\", \"Hema\", \"Hemant\", \"Himani\", \"Hira\", \"Hiren\", \"Indira\", \"Indra\", \"Indu\", \"Ira\", \"Ishan\", \"Isha\",\n",
    "        \"Ishaan\", \"Ishani\", \"Ishita\", \"Jai\", \"Jatin\", \"Jaya\", \"Jayant\", \"Jayanti\", \"Jayin\", \"Jhanvi\", \"Jitendra\", \"Jiya\", \"Jyoti\", \"Kabir\", \"Kalindi\", \"Kalpana\", \"Kalyani\", \"Kanak\", \"Karan\", \"Karthik\",\n",
    "        \"Kartik\", \"Karuna\", \"Kaustubh\", \"Kavita\", \"Kavya\", \"Keerthi\", \"Keshav\", \"Ketan\", \"Khushi\", \"Kiara\", \"Kiran\", \"Kirti\", \"Krishna\", \"Krish\", \"Kriti\", \"Kritika\", \"Kshitij\", \"Kunal\", \"Kushal\", \"Lakshmi\",\n",
    "        \"Lalit\", \"Lalita\", \"Lavanya\", \"Laxmi\", \"Leela\", \"Madhav\", \"Madhavi\", \"Madhur\", \"Mahendra\", \"Mahesh\", \"Mahima\", \"Mahi\", \"Mallika\", \"Manasi\", \"Manish\", \"Manju\", \"Manjula\", \"Manoj\", \"Manohar\", \"Maya\",\n",
    "        \"Mayank\", \"Meena\", \"Meera\", \"Megha\", \"Mehul\", \"Mira\", \"Mitali\", \"Mohit\", \"Mridula\", \"Mukesh\", \"Mukta\", \"Muskaan\", \"Nachiket\", \"Naman\", \"Namita\", \"Nandini\", \"Narayan\", \"Naren\", \"Naveen\", \"Navin\",\n",
    "        \"Neela\", \"Neelam\", \"Neeti\", \"Neha\", \"Nidhi\", \"Nikhil\", \"Nikita\", \"Nilam\", \"Nilesh\", \"Nilima\", \"Nimesh\", \"Nirmal\", \"Nirmala\", \"Nirupama\", \"Nisha\", \"Nishant\", \"Nishtha\", \"Nitesh\", \"Niti\", \"Nitya\",\n",
    "        \"Om\", \"Ojas\", \"Omkar\", \"Pankaj\", \"Parag\", \"Paras\", \"Parth\", \"Parvati\", \"Pooja\", \"Prabhat\", \"Prachi\", \"Pradip\", \"Pragya\", \"Prakash\", \"Pramod\", \"Pranav\", \"Praney\", \"Pranita\", \"Prasad\", \"Pratap\",\n",
    "        \"Pratibha\", \"Pratik\", \"Praveen\", \"Prem\", \"Prerna\", \"Preeti\", \"Priya\", \"Priyanka\", \"Puja\", \"Puneet\", \"Purvi\", \"Pushpa\", \"Rachana\", \"Radha\", \"Radhika\", \"Raghu\", \"Rahul\", \"Raj\", \"Raja\", \"Rajat\",\n",
    "        \"Rajeev\", \"Rajendra\", \"Rajesh\", \"Raju\", \"Rakesh\", \"Ram\", \"Rama\", \"Ramesh\", \"Rani\", \"Ranjana\", \"Ranjit\", \"Rashmi\", \"Ravi\", \"Ravindra\", \"Rekha\", \"Renuka\", \"Reva\", \"Richa\", \"Riddhi\", \"Riddhima\",\n",
    "        \"Rishabh\", \"Rishi\", \"Rita\", \"Ritesh\", \"Ritika\", \"Rohan\", \"Rohit\", \"Roopa\", \"Ruchi\", \"Rudra\", \"Rupal\", \"Rupali\", \"Rushil\", \"Sachin\", \"Sahil\", \"Sakshi\", \"Sameer\", \"Samir\", \"Sandeep\", \"Sandya\",\n",
    "        \"Sanjay\", \"Sanjiv\", \"Sankar\", \"Santosh\", \"Saras\", \"Sarika\", \"Sarthak\", \"Satish\", \"Satyam\", \"Saurabh\", \"Savar\", \"Seema\", \"Shailesh\", \"Shalu\", \"Shanta\", \"Shantanu\", \"Sharad\", \"Sharmila\", \"Shashi\", \"Shekhar\",\n",
    "        \"Shilpa\", \"Shiva\", \"Shivani\", \"Shraddha\", \"Shreeya\", \"Shreya\", \"Shri\", \"Shriram\", \"Shubha\", \"Shubham\", \"Shweta\", \"Siddharth\", \"Simar\", \"Simran\", \"Smita\", \"Smriti\", \"Sneha\", \"Soham\", \"Sohini\", \"Sonam\",\n",
    "        \"Sonia\", \"Srijan\", \"Srinivas\", \"Subhash\", \"Suchitra\", \"Sudhir\", \"Sujata\", \"Sukanya\", \"Suman\", \"Sumati\", \"Sumit\", \"Sundar\", \"Sundari\", \"Sunil\", \"Sunita\", \"Supriya\", \"Suraj\", \"Suresh\", \"Surya\", \"Sushil\",\n",
    "        \"Sushma\", \"Swapna\", \"Swapnil\", \"Swati\", \"Tanisha\", \"Tanmay\", \"Tanuj\", \"Tanvi\", \"Tanya\", \"Tarun\", \"Tej\", \"Tejas\", \"Tejashri\", \"Tina\", \"Trisha\", \"Triveni\", \"Tuhina\", \"Tushar\", \"Udai\", \"Uday\",\n",
    "        \"Ujjwal\", \"Uma\", \"Umang\", \"Upasana\", \"Urvi\", \"Usha\", \"Uttam\", \"Vaibhav\", \"Vaishnavi\", \"Varun\", \"Varsha\", \"Vasant\", \"Vasudha\", \"Vedant\", \"Vidhi\", \"Vidya\", \"Vijay\", \"Vimal\", \"Vinay\", \"Vineet\",\n",
    "        \"Vinod\", \"Vipul\", \"Viraj\", \"Vishal\", \"Vishnu\", \"Vivek\", \"Yash\", \"Yashoda\", \"Yogesh\", \"Yuvraj\"\n",
    "    ]\n",
    "\n",
    "    indian_surnames = [\n",
    "        \"Acharya\", \"Agarwal\", \"Aggarwal\", \"Ahluwalia\", \"Ahuja\", \"Arora\", \"Anand\", \"Awasthi\", \"Babu\", \"Badal\", \"Bajaj\", \"Bajwa\", \"Bakshi\", \"Balakrishnan\", \"Balan\", \"Balasubramanian\", \"Banerjee\", \"Banik\", \"Bansal\", \"Basu\",\n",
    "        \"Batra\", \"Bhagat\", \"Bhalla\", \"Bhandari\", \"Bhardwaj\", \"Bhargava\", \"Bhasin\", \"Bhat\", \"Bhatia\", \"Bhatt\", \"Bhattacharya\", \"Bhavsar\", \"Bedi\", \"Bhojwani\", \"Bose\", \"Buch\", \"Chauhan\", \"Chadha\", \"Chakrabarti\", \"Chakraborty\",\n",
    "        \"Chandra\", \"Chatterjee\", \"Chaturvedi\", \"Chauhan\", \"Chawla\", \"Cherian\", \"Chokshi\", \"Chopra\", \"Choudhary\", \"Choudhury\", \"D'Souza\", \"Dalmia\", \"Das\", \"Dasgupta\", \"Datta\", \"Dave\", \"Dayal\", \"Desai\", \"Deshmukh\", \"Deshpande\",\n",
    "        \"Devan\", \"Dewan\", \"Dhar\", \"Dhawan\", \"Dhillon\", \"Dixit\", \"Doshi\", \"Dua\", \"Dube\", \"Dubey\", \"Dugar\", \"Dutt\", \"Dutta\", \"Dwivedi\", \"Fernandes\", \"Gandhi\", \"Ganesh\", \"Ganguly\", \"Garg\", \"George\", \"Ghosh\", \"Gokhale\", \"Goel\",\n",
    "        \"Goswami\", \"Gour\", \"Goyal\", \"Guha\", \"Gulati\", \"Gupta\", \"Halder\", \"Handa\", \"Hans\", \"Hegde\", \"Hora\", \"Iyengar\", \"Iyer\", \"Jain\", \"Jaiswal\", \"Jani\", \"Jayaraman\", \"Jha\", \"Jhaveri\", \"Johar\", \"Joshi\", \"Kakkar\", \"Kala\",\n",
    "        \"Kale\", \"Kalra\", \"Kanda\", \"Kannan\", \"Kapoor\", \"Kapur\", \"Kar\", \"Karnik\", \"Kashyap\", \"Kaul\", \"Kaur\", \"Khatri\", \"Khanna\", \"Khandelwal\", \"Kher\", \"Khosla\", \"Khurana\", \"Kohli\", \"Kochhar\", \"Kothari\", \"Krishna\", \"Krishnamurthy\",\n",
    "        \"Krishnan\", \"Kulkarni\", \"Kumar\", \"Kumari\", \"Kurian\", \"Kuruvilla\", \"Lal\", \"Lalla\", \"Lamba\", \"Lobo\", \"Madhavan\", \"Mahajan\", \"Mahalingam\", \"Maheshwari\", \"Majumdar\", \"Malhotra\", \"Malik\", \"Manikandan\", \"Mani\", \"Manna\",\n",
    "        \"Mathew\", \"Mathur\", \"Mehra\", \"Mehrotra\", \"Mehta\", \"Menon\", \"Mirchandani\", \"Mishra\", \"Misra\", \"Mistry\", \"Mitra\", \"Modi\", \"Mohan\", \"Mohanty\", \"Mukherjee\", \"Mukhopadhyay\", \"Nagar\", \"Nagarajan\", \"Nair\", \"Nambiar\",\n",
    "        \"Nambudiripad\", \"Nanda\", \"Narang\", \"Narayan\", \"Narayanan\", \"Nath\", \"Nayak\", \"Nayar\", \"Nazareth\", \"Nigam\", \"Nimbkar\", \"Oak\", \"Om\", \"Padmanabhan\", \"Pai\", \"Pal\", \"Palan\", \"Pande\", \"Pandey\", \"Pandit\", \"Pant\", \"Parekh\",\n",
    "        \"Parikh\", \"Patel\", \"Pathak\", \"Patil\", \"Patnaik\", \"Patra\", \"Pillai\", \"Prabhakar\", \"Prabhu\", \"Pradhan\", \"Prakash\", \"Prasad\", \"Prashad\", \"Puri\", \"Purohit\", \"Radhakrishnan\", \"Ragavan\", \"Raghavan\", \"Rai\", \"Raj\", \"Raja\",\n",
    "        \"Rajan\", \"Rajagopalan\", \"Raju\", \"Ram\", \"Rama\", \"Raman\", \"Ramanathan\", \"Ramaswamy\", \"Ramachandran\", \"Ramakrishnan\", \"Rangan\", \"Ranganathan\", \"Rao\", \"Rastogi\", \"Ratta\", \"Rattan\", \"Ratti\", \"Rau\", \"Raval\", \"Ravindran\",\n",
    "        \"Ray\", \"Reddy\", \"Roy\", \"Sabharwal\", \"Sachdev\", \"Sachdeva\", \"Sagar\", \"Saha\", \"Sahni\", \"Saini\", \"Salvi\", \"Samarth\", \"Sampath\", \"Sampat\", \"Samuel\", \"Sandhu\", \"Sane\", \"Sanghi\", \"Sanghvi\", \"Sankar\", \"Sankaran\", \"Sant\",\n",
    "        \"Saraf\", \"Sarin\", \"Sarkar\", \"Sarma\", \"Sarna\", \"Sastry\", \"Sathe\", \"Savant\", \"Sawhney\", \"Saxena\", \"Sebastian\", \"Sehgal\", \"Sen\", \"Sengupta\", \"Sequeira\", \"Seth\", \"Sethi\", \"Setty\", \"Shah\", \"Shankar\", \"Sharma\", \"Shenoy\",\n",
    "        \"Sheth\", \"Shetty\", \"Shroff\", \"Shukla\", \"Sinha\", \"Sodhi\", \"Solanki\", \"Som\", \"Soman\", \"Somani\", \"Soni\", \"Sood\", \"Sridhar\", \"Srinivas\", \"Srinivasan\", \"Srivastava\", \"Subramaniam\", \"Subramanian\", \"Sundaram\", \"Sur\", \"Suri\",\n",
    "        \"Swaminathan\", \"Swamy\", \"Tagore\", \"Talwar\", \"Tandon\", \"Tata\", \"Tella\", \"Thakkar\", \"Thakur\", \"Thomas\", \"Tiwari\", \"Trivedi\", \"Upadhyay\", \"Upadhyaya\", \"Vaidya\", \"Varghese\", \"Varkey\", \"Varma\", \"Varman\", \"Vasa\", \"Venkataraman\",\n",
    "        \"Venkatesh\", \"Verma\", \"Vijayakumar\", \"Virk\", \"Viswanathan\", \"Vohra\", \"Vora\", \"Vyas\", \"Wable\", \"Wadhwa\", \"Wagle\", \"Wahi\", \"Walia\", \"Walla\", \"Warrior\", \"Wason\", \"Yadav\", \"Yogi\", \"Zaveri\", \"Zachariah\"\n",
    "    ]\n",
    "    \n",
    "    given_name = random.choice(indian_given_names)\n",
    "    surname = random.choice(indian_surnames)\n",
    "    \n",
    "    return f\"{given_name} {surname}\"\n",
    "\n",
    "def generate_name():\n",
    "    name_generators = [generate_chinese_name, generate_malay_name, generate_indian_name]\n",
    "    chosen_generator = random.choice(name_generators)\n",
    "    return chosen_generator(), chosen_generator\n",
    "\n",
    "\n",
    "\n",
    "def generate_nric():\n",
    "    digits = ''.join(random.choices(string.digits, k=8))\n",
    "    checksum = random.choice(string.ascii_uppercase)\n",
    "    return f\"S{digits}{checksum}\"\n",
    "\n",
    "def generate_phone_number():\n",
    "    return f\"+65 {random.randint(8000, 9999)} {random.randint(1000, 9999)}\"\n",
    "\n",
    "def generate_drivers_license():\n",
    "    return f\"S{random.randint(1000000, 9999999):07d}{random.choice(string.ascii_uppercase)}\"\n",
    "\n",
    "def generate_cpf_number():\n",
    "    return f\"S{random.randint(1000000, 9999999):07d}{random.choice(string.ascii_uppercase)}\"\n",
    "\n",
    "def calculate_age(dob):\n",
    "    today = datetime.now()\n",
    "    return today.year - dob.year - ((today.month, today.day) < (dob.month, dob.day))\n",
    "\n",
    "def generate_passport_number():\n",
    "    return f\"K{random.randint(1000000, 9999999)}{random.choice(string.ascii_uppercase)}\"\n",
    "\n",
    "\n",
    "\n",
    "def generate_date(start_date, end_date):\n",
    "    time_between_dates = end_date - start_date\n",
    "    days_between_dates = time_between_dates.days\n",
    "    random_number_of_days = random.randrange(days_between_dates)\n",
    "    return start_date + timedelta(days=random_number_of_days)\n",
    "\n",
    "def generate_profile():\n",
    "    countries = [\"Singapore\", \"Malaysia\", \"China\", \"India\", \"Indonesia\", \"Philippines\", \"Vietnam\", \"Thailand\", \"Myanmar\", \"Cambodia\", \"Laos\", \"Brunei\", \"Japan\", \"South Korea\", \"North Korea\", \"Taiwan\", \"Hong Kong\", \"Macau\", \"Bangladesh\", \"Sri Lanka\", \"Nepal\", \"Bhutan\", \"Pakistan\", \"Afghanistan\", \"Iran\", \"Iraq\", \"Saudi Arabia\", \"UAE\", \"Oman\", \"Yemen\", \"Qatar\", \"Kuwait\", \"Bahrain\", \"Jordan\", \"Lebanon\", \"Syria\", \"Israel\", \"Palestine\", \"Turkey\", \"Cyprus\", \"Greece\", \"Italy\", \"Spain\", \"Portugal\", \"France\", \"Germany\", \"United Kingdom\", \"Ireland\", \"Netherlands\", \"Belgium\", \"Luxembourg\", \"Switzerland\", \"Austria\", \"Czech Republic\", \"Slovakia\", \"Hungary\", \"Poland\", \"Romania\", \"Bulgaria\", \"Serbia\", \"Croatia\", \"Bosnia and Herzegovina\", \"Montenegro\", \"North Macedonia\", \"Albania\", \"Kosovo\", \"Slovenia\", \"United States\", \"Canada\", \"Mexico\", \"Brazil\", \"Argentina\", \"Chile\", \"Peru\", \"Colombia\", \"Venezuela\", \"Ecuador\", \"Bolivia\", \"Paraguay\", \"Uruguay\", \"Guyana\", \"Suriname\", \"French Guiana\", \"Australia\", \"New Zealand\", \"Papua New Guinea\", \"Fiji\", \"Solomon Islands\", \"Vanuatu\", \"New Caledonia\", \"Egypt\", \"Libya\", \"Tunisia\", \"Algeria\", \"Morocco\", \"Sudan\", \"South Sudan\", \"Ethiopia\", \"Eritrea\", \"Djibouti\", \"Somalia\", \"Kenya\", \"Uganda\", \"Tanzania\", \"Rwanda\", \"Burundi\", \"Congo\", \"Democratic Republic of the Congo\", \"Angola\", \"Zambia\", \"Zimbabwe\", \"Mozambique\", \"Malawi\", \"South Africa\", \"Namibia\", \"Botswana\", \"Lesotho\", \"Eswatini\"]\n",
    "\n",
    "    occupations = [\"Teacher\", \"Engineer\", \"Doctor\", \"Lawyer\", \"Accountant\", \"Nurse\", \"Salesperson\", \"Manager\", \"Chef\", \"Artist\", \"Software Developer\", \"Data Scientist\", \"Architect\", \"Pharmacist\", \"Dentist\", \"Veterinarian\", \"Police Officer\", \"Firefighter\", \"Paramedic\", \"Pilot\", \"Flight Attendant\", \"Electrician\", \"Plumber\", \"Carpenter\", \"Mechanic\", \"Hairdresser\", \"Beautician\", \"Photographer\", \"Journalist\", \"Writer\", \"Editor\", \"Translator\", \"Interpreter\", \"Psychologist\", \"Counselor\", \"Social Worker\", \"Financial Advisor\", \"Insurance Agent\", \"Real Estate Agent\", \"Marketing Specialist\", \"Public Relations Specialist\", \"Human Resources Manager\", \"Graphic Designer\", \"Web Designer\", \"UX Designer\", \"Product Manager\", \"Project Manager\", \"Business Analyst\", \"Systems Analyst\", \"Network Administrator\", \"Database Administrator\", \"Cybersecurity Specialist\", \"Librarian\", \"Museum Curator\", \"Zoologist\", \"Marine Biologist\", \"Environmental Scientist\", \"Geologist\", \"Meteorologist\", \"Astronomer\", \"Physicist\", \"Chemist\", \"Biologist\", \"Mathematician\", \"Statistician\", \"Economist\", \"Political Scientist\", \"Sociologist\", \"Anthropologist\", \"Archaeologist\", \"Historian\", \"Philosopher\", \"Theologian\", \"Actor\", \"Musician\", \"Dancer\", \"Choreographer\", \"Film Director\", \"Producer\", \"Screenwriter\", \"Fashion Designer\", \"Interior Designer\", \"Landscape Architect\", \"Urban Planner\", \"Civil Engineer\", \"Mechanical Engineer\", \"Electrical Engineer\", \"Chemical Engineer\", \"Aerospace Engineer\", \"Biomedical Engineer\", \"Environmental Engineer\", \"Nuclear Engineer\", \"Petroleum Engineer\", \"Agricultural Engineer\", \"Food Scientist\", \"Nutritionist\", \"Dietitian\", \"Personal Trainer\", \"Sports Coach\", \"Athlete\", \"Referee\", \"Umpire\", \"Tour Guide\", \"Travel Agent\", \"Hotel Manager\", \"Restaurant Manager\", \"Bartender\", \"Waiter/Waitress\", \"Housekeeping Staff\", \"Janitor\", \"Security Guard\", \"Locksmith\", \"Tailor\", \"Seamstress\", \"Jeweler\", \"Watchmaker\", \"Optician\", \"Optometrist\", \"Audiologist\", \"Speech Therapist\", \"Occupational Therapist\", \"Physical Therapist\", \"Massage Therapist\", \"Chiropractor\", \"Acupuncturist\", \"Naturopath\", \"Homeopath\", \"Midwife\", \"Doula\", \"Farmer\", \"Rancher\", \"Fisherman\", \"Forester\", \"Gardener\", \"Florist\", \"Botanist\", \"Zoologist\", \"Entomologist\", \"Paleontologist\", \"Geographer\", \"Cartographer\", \"Surveyor\", \"Air Traffic Controller\", \"Ship Captain\", \"Train Conductor\", \"Bus Driver\", \"Taxi Driver\", \"Truck Driver\", \"Courier\", \"Postal Worker\", \"Librarian\", \"Archivist\", \"Curator\", \"Conservator\", \"Restorer\", \"Printer\", \"Bookbinder\", \"Engraver\", \"Sculptor\", \"Painter\", \"Illustrator\", \"Animator\", \"Game Designer\", \"Voice Actor\", \"Stunt Performer\", \"Magician\", \"Circus Performer\", \"Street Performer\", \"Busker\", \"Tattoo Artist\", \"Piercer\", \"Makeup Artist\", \"Special Effects Artist\", \"Prosthetics Technician\", \"Orthodontist\", \"Endodontist\", \"Periodontist\", \"Oral Surgeon\", \"Radiologist\", \"Anesthesiologist\", \"Surgeon\", \"Cardiologist\", \"Neurologist\", \"Oncologist\", \"Pediatrician\", \"Geriatrician\", \"Psychiatrist\", \"Dermatologist\", \"Gynecologist\", \"Urologist\", \"Ophthalmologist\", \"Otolaryngologist\", \"Podiatrist\", \"Nephrologist\", \"Pulmonologist\", \"Rheumatologist\", \"Gastroenterologist\", \"Endocrinologist\", \"Hematologist\", \"Immunologist\", \"Pathologist\", \"Forensic Scientist\", \"Toxicologist\", \"Biochemist\", \"Microbiologist\", \"Virologist\", \"Geneticist\", \"Embryologist\", \"Ecologist\", \"Oceanographer\", \"Seismologist\", \"Volcanologist\", \"Hydrologist\", \"Glaciologist\", \"Climatologist\", \"Astronaut\", \"Cosmonaut\", \"Taikonaut\"]\n",
    "\n",
    "    languages = [\"English\", \"Mandarin\", \"Malay\", \"Tamil\", \"Hokkien\", \"Cantonese\", \"Teochew\", \"Hakka\", \"Hainanese\", \"Hindi\", \"Bengali\", \"Urdu\", \"Punjabi\", \"Gujarati\", \"Malayalam\", \"Telugu\", \"Kannada\", \"Marathi\", \"Tagalog\", \"Indonesian\", \"Vietnamese\", \"Thai\", \"Burmese\", \"Khmer\", \"Lao\", \"Japanese\", \"Korean\", \"Arabic\", \"Persian\", \"Turkish\", \"Russian\", \"French\", \"German\", \"Spanish\", \"Portuguese\", \"Italian\", \"Greek\", \"Dutch\", \"Swedish\", \"Norwegian\", \"Danish\", \"Finnish\", \"Polish\", \"Czech\", \"Slovak\", \"Hungarian\", \"Romanian\", \"Bulgarian\", \"Serbian\", \"Croatian\", \"Bosnian\", \"Albanian\", \"Macedonian\", \"Slovenian\", \"Ukrainian\", \"Belarusian\", \"Lithuanian\", \"Latvian\", \"Estonian\", \"Georgian\", \"Armenian\", \"Azerbaijani\", \"Kazakh\", \"Uzbek\", \"Turkmen\", \"Kyrgyz\", \"Tajik\", \"Mongolian\", \"Tibetan\", \"Nepali\", \"Sinhala\", \"Dzongkha\", \"Tetum\", \"Fijian\", \"Samoan\", \"Tongan\", \"Maori\", \"Hawaiian\", \"Swahili\", \"Zulu\", \"Xhosa\", \"Afrikaans\", \"Amharic\", \"Somali\", \"Yoruba\", \"Igbo\", \"Hausa\", \"Wolof\", \"Fulani\", \"Oromo\", \"Hebrew\", \"Yiddish\", \"Latin\", \"Ancient Greek\", \"Sanskrit\", \"Classical Chinese\", \"Esperanto\"]\n",
    "\n",
    "    blood_types = [\"A+\", \"A-\", \"B+\", \"B-\", \"O+\", \"O-\", \"AB+\", \"AB-\"]\n",
    "\n",
    "    ns_ranks = [\"Private\", \"Lance Corporal\", \"Corporal\", \"Sergeant\", \"Staff Sergeant\", \"2nd Lieutenant\", \"Lieutenant\", \"Captain\"]\n",
    "\n",
    "    marital_statuses = [\"Single\", \"Married\", \"Divorced\", \"Separated\", \"Widowed\", \"Civil Partnership\", \"Domestic Partnership\", \"Engaged\", \"Annulled\"]\n",
    "\n",
    "    religions = [\"Buddhism\", \"Christianity\", \"Islam\", \"Hinduism\", \"Taoism\", \"No Religion\"]\n",
    "    \n",
    "    dob = generate_date(datetime(1950, 1, 1), datetime(2024, 12, 31))\n",
    "\n",
    "    towns = [\n",
    "    \"Ang Mo Kio\", \"Bedok\", \"Tampines\", \"Woodlands\", \"Jurong West\", \"Sengkang\", \"Punggol\",\n",
    "    \"Yishun\", \"Hougang\", \"Jurong East\", \"Choa Chu Kang\", \"Bukit Batok\", \"Toa Payoh\",\n",
    "    \"Serangoon\", \"Bukit Merah\", \"Pasir Ris\", \"Clementi\", \"Bishan\", \"Queenstown\",\n",
    "    \"Bukit Panjang\", \"Kallang\", \"Geylang\", \"Marine Parade\", \"Novena\", \"Tanjong Pagar\",\n",
    "    \"Bukit Timah\", \"Sembawang\", \"Central Area\", \"Rochor\", \"Orchard\", \"Newton\",\n",
    "    \"Outram\", \"River Valley\", \"Downtown Core\", \"Marina South\", \"Straits View\"\n",
    "    ]\n",
    "\n",
    "    streets = [\n",
    "        \"Orchard Road\", \"Serangoon Road\", \"Shenton Way\", \"Raffles Place\", \"Boon Lay Way\",\n",
    "        \"Jurong Gateway Road\", \"Ang Mo Kio Avenue 3\", \"Tampines Avenue 5\", \"Woodlands Avenue 1\",\n",
    "        \"Bedok North Street 1\", \"Punggol Central\", \"Sengkang East Way\", \"Yishun Ring Road\",\n",
    "        \"Hougang Avenue 7\", \"Choa Chu Kang Avenue 4\", \"Bukit Batok East Avenue 3\",\n",
    "        \"Toa Payoh Lorong 1\", \"Bishan Street 22\", \"Clementi Avenue 3\", \"Marine Parade Road\",\n",
    "        \"Pasir Ris Drive 1\", \"Upper Serangoon Road\", \"Upper Thomson Road\", \"Bukit Timah Road\",\n",
    "        \"Jalan Besar\", \"Victoria Street\", \"North Bridge Road\", \"South Bridge Road\",\n",
    "        \"New Upper Changi Road\", \"Eu Tong Sen Street\", \"Telok Blangah Road\", \"Alexandra Road\",\n",
    "        \"Joo Chiat Road\", \"Geylang Road\", \"Kallang Way\", \"Lavender Street\", \"Beach Road\",\n",
    "        \"Balestier Road\", \"Bartley Road\", \"Braddell Road\", \"Bukit Panjang Ring Road\",\n",
    "        \"Commonwealth Avenue\", \"Holland Road\", \"East Coast Road\", \"Sembawang Road\",\n",
    "        \"Mandai Road\", \"Changi Road\", \"Upper East Coast Road\", \"Loyang Avenue\",\n",
    "        \"Admiralty Drive\", \"Yio Chu Kang Road\", \"Lorong Chuan\", \"Kovan Road\", \"Simei Street 1\"\n",
    "    ]\n",
    "    work_pass_types = [\"Employment Pass\", \"S Pass\", \"Work Permit\", \"Dependent's Pass\", \"Long Term Visit Pass\"]\n",
    "    language_proficiencies = [\"Basic\", \"Conversational\", \"Fluent\", \"Native\"]\n",
    "\n",
    "    races = [\"Chinese\", \"Malay\", \"Indian\", \"Others\"]\n",
    "    religions = [\"Buddhism\", \"Christianity\", \"Islam\", \"Hinduism\", \"Taoism\", \"No Religion\"]\n",
    "    towns = [\"Ang Mo Kio\", \"Bedok\", \"Tampines\", \"Woodlands\", \"Jurong West\", \"Sengkang\", \"Punggol\"]\n",
    "    email_providers = [\"gmail.com\", \"hotmail.com\", \"yahoo.com\", \"outlook.com\"]\n",
    "    sg_qualifications = [\"PSLE\", \"N-Levels\", \"O-Levels\", \"A-Levels\", \"Diploma\", \"Bachelor's\", \"Master's\", \"PhD\"]\n",
    "    language_proficiencies = [\"Basic\", \"Conversational\", \"Fluent\", \"Native\"]\n",
    "    ns_statuses = [\"Pre-enlistee\", \"NSF\", \"NSman\", \"Exempted\"]\n",
    "    ns_ranks = [\"Private\", \"Lance Corporal\", \"Corporal\", \"Sergeant\", \"Staff Sergeant\", \"2nd Lieutenant\", \"Lieutenant\", \"Captain\"]\n",
    "    work_pass_types = [\"Employment Pass\", \"S Pass\", \"Work Permit\", \"Dependent's Pass\", \"Long Term Visit Pass\"]\n",
    "\n",
    "    citizenship=random.choice([\"Singapore Citizen\", \"Singapore PR\", \"Foreigner\"])\n",
    "    name, name_generator=generate_name()\n",
    "    profile = {\n",
    "        \"nric\": generate_nric(),\n",
    "        \"name\": name_generator(),  # Assume this function generates culturally appropriate names\n",
    "        \"race\": random.choice(races),\n",
    "        \"gender\": random.choice([\"Male\", \"Female\"]),\n",
    "        \"date_of_birth\": (datetime.now() - timedelta(days=random.randint(6570, 36500))).strftime(\"%Y-%m-%d\"),\n",
    "        \"age\": 0,  # Will be calculated later\n",
    "        \"country_of_birth\": random.choice(countries),\n",
    "        \"citizenship\": citizenship,\n",
    "        \"religion\": random.choice(religions),\n",
    "        \"marital_status\": random.choice(marital_statuses),\n",
    "        \"address\": {\n",
    "            \"block\": f\"{random.randint(1, 999)}\",\n",
    "            \"street No.\": f\"{random.randint(1, 999)}\",\n",
    "            \"street\": f\"{random.choice(streets)}\",\n",
    "            \"unit\": f\"#{random.randint(1, 30)}-{random.randint(1, 999):03d}\",\n",
    "            \"town\": random.choice(towns),\n",
    "            \"postal_code\": f\"{random.randint(100000, 999999)}\"\n",
    "        },\n",
    "        \"phone_number\": generate_phone_number(),\n",
    "        \"email\": generate_random_email(),\n",
    "        \"occupation\": random.choice(occupations),\n",
    "        \"cpf_number\": generate_cpf_number(),\n",
    "        \"education\": {\n",
    "            \"highest_qualification\": random.choice(sg_qualifications),\n",
    "            \"institution\": random.choice([\"NUS\", \"NTU\", \"SMU\", \"SUTD\", \"Local Polytechnic\", \"Local JC\", \"Others\"])\n",
    "        },\n",
    "        \"languages\": {\n",
    "            \"spoken\": {lang: random.choice(language_proficiencies) for lang in random.sample(languages, random.randint(1, 3))},\n",
    "            \"written\": {lang: random.choice(language_proficiencies) for lang in random.sample(languages, random.randint(1, 3))}\n",
    "        },\n",
    "        \"height_cm\": random.randint(150, 190),\n",
    "        \"weight_kg\": random.randint(45, 100),\n",
    "        \"blood_type\": random.choice(blood_types),\n",
    "        \"passport_number\": generate_passport_number(),\n",
    "        \"drivers_license_number\": generate_drivers_license(),\n",
    "        \"national_service\": {\n",
    "            \"status\": None,\n",
    "            \"rank\": None\n",
    "        },\n",
    "        \"immigration_status\": None,  # Will be filled for non-citizens\n",
    "        \"emergency_contact\": {\n",
    "            \"name\": name_generator(),\n",
    "            \"relationship\": random.choice([\"Parent\", \"Sibling\", \"Spouse\", \"Friend\"]),\n",
    "            \"phone_number\": generate_phone_number()\n",
    "        },\n",
    "        \"deceased\": random.choice([True, False])\n",
    "    }\n",
    "\n",
    "    # Calculate age\n",
    "    profile[\"age\"] = calculate_age(datetime.strptime(profile[\"date_of_birth\"], \"%Y-%m-%d\"))\n",
    "\n",
    "    # Set NS status for males\n",
    "    if profile[\"gender\"] == \"Male\" and profile[\"citizenship\"] in [\"Singapore Citizen\", \"Singapore PR\"]:\n",
    "        if profile[\"age\"] < 18:\n",
    "            profile[\"national_service\"][\"status\"] = \"Pre-enlistee\"\n",
    "        elif 18 <= profile[\"age\"] <= 20:\n",
    "            profile[\"national_service\"][\"status\"] = \"NSF\"\n",
    "            profile[\"national_service\"][\"rank\"] = random.choice(ns_ranks[:5])  # Lower ranks for NSF\n",
    "        elif profile[\"age\"] > 20:\n",
    "            profile[\"national_service\"][\"status\"] = \"NSman\"\n",
    "            profile[\"national_service\"][\"rank\"] = random.choice(ns_ranks)\n",
    "\n",
    "    # Set immigration status for non-citizens\n",
    "    if profile[\"citizenship\"] == \"Foreigner\":\n",
    "        profile[\"immigration_status\"] = random.choice(work_pass_types)\n",
    "\n",
    "    # Set date of death if deceased\n",
    "    if profile[\"deceased\"]:\n",
    "        # max_days = (datetime.now() - datetime.strptime(profile[\"date_of_birth\"], \"%Y-%m-%d\")).days\n",
    "        # profile[\"date_of_death\"] = (datetime.now() - timedelta(days=random.randint(0, max_days))).strftime(\"%Y-%m-%d\")\n",
    "        dob = datetime.strptime(profile[\"date_of_birth\"], \"%Y-%m-%d\")\n",
    "        age_in_days = profile[\"age\"] * 365  # This is an approximation, not accounting for leap years\n",
    "        date_of_death = dob + timedelta(days=age_in_days)\n",
    "        profile[\"date_of_death\"] = date_of_death.strftime(\"%Y-%m-%d\")\n",
    "    return profile\n",
    "\n",
    "def generate_profiles(n):\n",
    "    return [generate_profile() for _ in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def bulk_upload_pickle_to_elasticsearch(file_path, index_name, es, batch_size=1000):\n",
    "    \n",
    "    total_uploaded = 0\n",
    "    total_failed = 0\n",
    "    \n",
    "    def create_action(doc):\n",
    "        # doc=merge_nested_dictionaries(doc, default_template)\n",
    "        return {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": uuid.uuid4(),\n",
    "            \"_source\": doc\n",
    "        }\n",
    "\n",
    "    def read_and_upload_batch(data):\n",
    "        batch = []\n",
    "        for doc in data:\n",
    "            batch.append(create_action(doc))\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        if batch:\n",
    "            yield batch\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        for batch in read_and_upload_batch(data):\n",
    "            try:\n",
    "                success, failed = helpers.bulk(es, batch, raise_on_error=False)\n",
    "                if type(failed) is list: \n",
    "                    failed=len(failed)\n",
    "                total_uploaded += success\n",
    "                total_failed += failed\n",
    "                print(f\"Uploaded {success} documents, Failed {failed} documents\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error during bulk upload: {str(e)}\")\n",
    "                total_failed += len(batch)\n",
    "\n",
    "    return total_uploaded, total_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = generate_profiles(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': {'block': '827',\n",
      "             'postal_code': '705858',\n",
      "             'street': 'Commonwealth Avenue',\n",
      "             'street No.': '756',\n",
      "             'town': 'Sengkang',\n",
      "             'unit': '#15-042'},\n",
      " 'age': 65,\n",
      " 'blood_type': 'A+',\n",
      " 'citizenship': 'Singapore PR',\n",
      " 'country_of_birth': 'Slovakia',\n",
      " 'cpf_number': 'S8613060M',\n",
      " 'date_of_birth': '1958-10-05',\n",
      " 'deceased': False,\n",
      " 'drivers_license_number': 'S4707782F',\n",
      " 'education': {'highest_qualification': 'N-Levels',\n",
      "               'institution': 'Local Polytechnic'},\n",
      " 'email': 'mjq2n4xlpb@outlook.com',\n",
      " 'emergency_contact': {'name': 'Deng An Sheng',\n",
      "                       'phone_number': '+65 8163 9924',\n",
      "                       'relationship': 'Sibling'},\n",
      " 'gender': 'Male',\n",
      " 'height_cm': 166,\n",
      " 'immigration_status': None,\n",
      " 'languages': {'spoken': {'Afrikaans': 'Basic', 'Xhosa': 'Native'},\n",
      "               'written': {'Bengali': 'Native'}},\n",
      " 'marital_status': 'Married',\n",
      " 'name': 'Wong Jiu Zhan',\n",
      " 'national_service': {'rank': 'Captain', 'status': 'NSman'},\n",
      " 'nric': 'S77385949H',\n",
      " 'occupation': 'Sociologist',\n",
      " 'passport_number': 'K8013743A',\n",
      " 'phone_number': '+65 9395 8462',\n",
      " 'race': 'Others',\n",
      " 'religion': 'Taoism',\n",
      " 'weight_kg': 92}\n"
     ]
    }
   ],
   "source": [
    "pprint(profiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    es_endpoint = os.environ.get(\"ELASTIC_ENDPOINT\")\n",
    "    es_client = Elasticsearch(\n",
    "        es_endpoint,\n",
    "        api_key=os.environ.get(\"ELASTIC_API_KEY\")\n",
    "    )\n",
    "except Exception as e:\n",
    "    es_client=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=200\n",
    "profile_batch_size=1000\n",
    "\n",
    "for i in range(runs):\n",
    "    profiles = generate_profiles(profile_batch_size)\n",
    "    filename='./data/personal_info.pkl'\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(profiles, file)\n",
    "    try:\n",
    "        bulk_upload_pickle_to_elasticsearch(filename, os.environ.get(\"ELASTIC_DATA_INDEX\"), es_client)\n",
    "    except Exception as e:\n",
    "        print(traceback.print_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='''\n",
    "You are an AI assistant specialized in converting natural language queries into Elasticsearch queries. Your task is to interpret user questions about personal profiles and generate the appropriate Elasticsearch query in JSON format.\n",
    "\n",
    "The document schema for the profiles is as follows:\n",
    "\n",
    "{\n",
    "  \"nric\": \"string\",\n",
    "  \"name\": \"string\",\n",
    "  \"race\": \"string\",\n",
    "  \"gender\": \"string\",\n",
    "  \"date_of_birth\": \"date\",\n",
    "  \"age\": \"integer\",\n",
    "  \"country_of_birth\": \"string\",\n",
    "  \"citizenship\": \"string\",\n",
    "  \"religion\": \"string\" [\"Buddhism\", \"Christianity\", \"Islam\", \"Hinduism\", \"Taoism\", \"No Religion\"],\n",
    "  \"marital_status\": \"string\" [\"Single\", \"Married\", \"Divorced\", \"Separated\", \"Widowed\", \"Civil Partnership\", \"Domestic Partnership\", \"Engaged\", \"Annulled\"],\n",
    "  \"address\": {\n",
    "    \"block\": \"string\",\n",
    "    \"street_no\": \"string\",\n",
    "    \"street\": \"string\",\n",
    "    \"unit\": \"string\",\n",
    "    \"town\": \"string\",\n",
    "    \"postal_code\": \"string\"\n",
    "  },\n",
    "  \"phone_number\": \"string\",\n",
    "  \"email\": \"string\",\n",
    "  \"occupation\": \"string\",\n",
    "  \"cpf_number\": \"string\",\n",
    "  \"education\": {\n",
    "    \"highest_qualification\": \"string\",\n",
    "    \"institution\": \"string\"\n",
    "  },\n",
    "  \"languages\": {\n",
    "    \"spoken\": \"object\",\n",
    "    \"written\": \"object\"\n",
    "  },\n",
    "  \"height_cm\": \"integer\",\n",
    "  \"weight_kg\": \"integer\",\n",
    "  \"blood_type\": \"string\" [\"A+\", \"A-\", \"B+\", \"B-\", \"O+\", \"O-\", \"AB+\", \"AB-\"],\n",
    "  \"passport_number\": \"string\",\n",
    "  \"drivers_license_number\": \"string\",\n",
    "  \"national_service\": {\n",
    "    \"status\": \"string\",\n",
    "    \"rank\": \"string\"\n",
    "  },\n",
    "  \"immigration_status\": \"string\",\n",
    "  \"emergency_contact\": {\n",
    "    \"name\": \"string\",\n",
    "    \"relationship\": \"string\",\n",
    "    \"phone_number\": \"string\"\n",
    "  },\n",
    "  \"deceased\": \"boolean\",\n",
    "  \"date_of_death\": \"date\"\n",
    "}\n",
    "\n",
    "Example query:\n",
    "User: Find all male Singapore citizens between 25 and 30 years old who work as software developers and speak fluent English.\n",
    "\n",
    "Your response should be:\n",
    "\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"should\": [\n",
    "        { \"match\": { \"gender\": \"Male\" } },\n",
    "        { \"match\": { \"citizenship\": \"Singapore Citizen\" } },\n",
    "        { \"range\": { \"age\": { \"gte\": 25, \"lte\": 30 } } },\n",
    "        { \"match\": { \"occupation\": \"Software Developer\" } },\n",
    "        {\n",
    "          \"match\": {\n",
    "            \"languages.spoken.English\": {\n",
    "              \"query\": \"Fluent\",\n",
    "              \"fuzziness\": \"AUTO\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      \"minimum_should_match\": 2\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "Consider using multi_match for fields that might contain the value in different subfields:\n",
    "{\n",
    "  \"multi_match\": {\n",
    "    \"query\": \"Software Developer\",\n",
    "    \"fields\": [\"occupation\", \"job_title\", \"role\"],\n",
    "    \"type\": \"best_fields\",\n",
    "    \"fuzziness\": \"AUTO\"\n",
    "  }\n",
    "}\n",
    "\n",
    "For names or other fields where word order matters, you might want to use match_phrase with slop:\n",
    "{\n",
    "  \"match_phrase\": {\n",
    "    \"full_name\": {\n",
    "      \"query\": \"John Doe\",\n",
    "      \"slop\": 1\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "Generate a JSON query for Elasticsearch. Provide only the raw JSON without any surrounding tags or markdown formatting, because we need to convert your response to an object. \n",
    "Use a lenient approach with 'should' clauses instead of strict 'must' clauses. Include a 'minimum_should_match' parameter to ensure some relevance while allowing flexibility. Avoid using 'must' clauses entirely.\n",
    "All queries must be lowercase.\n",
    "\n",
    "Use 'match' queries instead of 'term' queries to allow for partial matches and spelling variations. Where appropriate, include fuzziness parameters to further increase tolerance for spelling differences. \n",
    "For name fields or other phrases where word order matters, consider using 'match_phrase' with a slop parameter. Use 'multi_match' for fields that might contain the value in different subfields.\n",
    "\n",
    "Now, please convert the following user query into an appropriate Elasticsearch query:\n",
    "\n",
    "[User's query goes here]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"All non-Singaporean men over the age of 25 who are software people living in woodlands\" \n",
    "\n",
    "response=LLM.generate_non_streaming_response(query, system_prompt=prompt)\n",
    "es_query=json.loads(response)\n",
    "pprint(es_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = es_client.search(index=os.environ.get(\"ELASTIC_DATA_INDEX\"), body=es_query)\n",
    "\n",
    "total_hits = search_results['hits']['total']['value']\n",
    "print(f\"Total matches: {total_hits}\")\n",
    "\n",
    "for hit in search_results['hits']['hits']:\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Name: {hit['_source']['name']}\")\n",
    "    print(f\"Age: {hit['_source']['age']}\")\n",
    "    print(f\"Gender: {hit['_source']['gender']}\")\n",
    "    print(f\"Citizenship: {hit['_source']['citizenship']}\")\n",
    "    print(f\"Occupation: {hit['_source']['occupation']}\")\n",
    "    print(f\"Address: {hit['_source']['address']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Women who are not alive currently, who are universal blood donors born in singapore\" \n",
    "\n",
    "response=LLM.generate_non_streaming_response(query, system_prompt=prompt)\n",
    "es_query=json.loads(response)\n",
    "pprint(es_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = es_client.search(index=os.environ.get(\"ELASTIC_DATA_INDEX\"), body=es_query)\n",
    "\n",
    "total_hits = search_results['hits']['total']['value']\n",
    "print(f\"Total matches: {total_hits}\")\n",
    "\n",
    "for hit in search_results['hits']['hits']:\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Name: {hit['_source']['name']}\")\n",
    "    print(f\"Blood Type: {hit['_source']['blood_type']}\")\n",
    "    print(f\"Gender: {hit['_source']['gender']}\")\n",
    "    print(f\"Country of Birth: {hit['_source']['country_of_birth']}\")\n",
    "    print(f\"Deceased: {hit['_source']['deceased']}\")\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
