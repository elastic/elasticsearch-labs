{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c2907fddfeac343a",
      "metadata": {
        "collapsed": false,
        "id": "c2907fddfeac343a",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "# Ensuring Semantic Precision With Minimum Score\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/supporting-blog-content/ensuring-semantic-precision-with-minimum-score/ensuring-semantic-precision-with-minimum-score.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "Learn how to use min_score with semantic text and hybrid search to improve precision. Please see [blog post for further context](https://www.elastic.co/search-labs/blog/semantic-precision-with-minimum-score)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3db37d2cf8264468",
      "metadata": {
        "collapsed": false,
        "id": "3db37d2cf8264468",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "## Requirements\n",
        "\n",
        "For this example, you will need:\n",
        "\n",
        "- An Elastic deployment:\n",
        "  - We'll be using [Elastic Cloud](https://www.elastic.co/guide/en/cloud/current/ec-getting-started.html) for this example (available with a [free trial](https://cloud.elastic.co/registration?onboarding_token=vectorsearch&utm_source=github&utm_content=elasticsearch-labs-notebook))\n",
        "\n",
        "- Elasticsearch 9.1 or above, or [Elasticsearch serverless](https://www.elastic.co/elasticsearch/serverless)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe1ed0703a8d1d3",
      "metadata": {
        "collapsed": false,
        "id": "7fe1ed0703a8d1d3",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "## Create Elastic Cloud deployment\n",
        "\n",
        "If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?onboarding_token=vectorsearch&utm_source=github&utm_content=elasticsearch-labs-notebook) for a free trial."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9c8bd62c8241f90",
      "metadata": {
        "collapsed": false,
        "id": "f9c8bd62c8241f90",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "## Install packages and connect with Elasticsearch Client\n",
        "\n",
        "To get started, we'll need to connect to our Elastic deployment using the Python client (version 8.15.0 or above).\n",
        "Because we're using an Elastic Cloud deployment, we'll use the **Cloud ID** to identify our deployment.\n",
        "\n",
        "First we need to `pip` install the following packages:\n",
        "\n",
        "- `elasticsearch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13fdf7656ced2da3",
      "metadata": {
        "id": "13fdf7656ced2da3",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "!pip install elasticsearch tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d54b112361d2f3d",
      "metadata": {
        "collapsed": false,
        "id": "9d54b112361d2f3d",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "Next, we need to import the modules we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a60627704e77ff6",
      "metadata": {
        "id": "9a60627704e77ff6",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from elasticsearch import Elasticsearch, helpers\n",
        "from getpass import getpass\n",
        "import json\n",
        "import gzip\n",
        "from tqdm.auto import tqdm as tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb9498124146d8bb",
      "metadata": {
        "collapsed": false,
        "id": "eb9498124146d8bb",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "Now we can instantiate the Python Elasticsearch client.\n",
        "\n",
        "First we prompt the user for their password and Cloud ID.\n",
        "Then we create a `client` object that instantiates an instance of the `Elasticsearch` class. üîê NOTE: getpass enables us to securely prompt the user for credentials without echoing them to the terminal, or storing it in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e14437dcce0f235",
      "metadata": {
        "id": "6e14437dcce0f235",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "# https://www.elastic.co/docs/deploy-manage/deploy/cloud-enterprise/connect-elasticsearch#ece-connect-endpoint\n",
        "ELASTIC_ENDPOINT = input(\"Elastic HTTPS Endpoint: \")\n",
        "\n",
        "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key\n",
        "ELASTIC_API_KEY = getpass(\"Elastic Api Key: \")\n",
        "\n",
        "# Create the client instance\n",
        "client = Elasticsearch(\n",
        "    hosts=[ELASTIC_ENDPOINT],\n",
        "    api_key=ELASTIC_API_KEY,\n",
        "    request_timeout=120\n",
        ")\n",
        "\n",
        "INDEX_NAME = \"search-movies\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbbdaf9118a97732",
      "metadata": {
        "collapsed": false,
        "id": "cbbdaf9118a97732",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "### Test the Client\n",
        "Before you continue, confirm that the client has connected with this test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cb0685fae12e034",
      "metadata": {
        "id": "4cb0685fae12e034",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "print(client.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59e2223bf2c4331",
      "metadata": {
        "collapsed": false,
        "id": "59e2223bf2c4331",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "Refer to [the documentation](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new) to learn how to connect to a self-managed deployment.\n",
        "\n",
        "Read [this page](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new) to learn how to connect using API keys."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6527366b",
      "metadata": {
        "id": "6527366b"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a2022756",
      "metadata": {
        "id": "a2022756"
      },
      "source": [
        "## Create Inference Service\n",
        "To allow for fast inference we will use the [inference service](https://www.elastic.co/docs/explore-analyze/elastic-inference/eis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28fe9c4c",
      "metadata": {
        "id": "28fe9c4c"
      },
      "outputs": [],
      "source": [
        "client.inference.put(task_type='sparse_embedding', inference_id='movie-inference',\n",
        "                    body = {\n",
        "                        \"service\": \"elastic\",\n",
        "                        \"service_settings\": {\n",
        "                            \"model_id\": \"elser\"\n",
        "                        }\n",
        "                    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "818f7a72a83b5776",
      "metadata": {
        "collapsed": false,
        "id": "818f7a72a83b5776",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "## Create the Index\n",
        "\n",
        "Now we need to create the movie index. Note that this code deletes any existing index with the same name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace87760606f67c6",
      "metadata": {
        "id": "ace87760606f67c6",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "client.indices.delete(index=INDEX_NAME, ignore_unavailable=True)\n",
        "client.indices.create(\n",
        "    index=INDEX_NAME,\n",
        "    mappings={\n",
        "    \"dynamic\": \"true\",\n",
        "    \"dynamic_templates\": [\n",
        "      {\n",
        "        \"all_text_fields\": {\n",
        "          \"match_mapping_type\": \"string\",\n",
        "          \"mapping\": {\n",
        "            \"analyzer\": \"english\",\n",
        "            \"fields\": {\n",
        "              \"keyword\": {\n",
        "                \"ignore_above\": 2048,\n",
        "                \"type\": \"keyword\"\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    ],\n",
        "    \"properties\": {\n",
        "      \"title\": {\n",
        "        \"type\": \"text\"\n",
        "      },\n",
        "      \"overview\": {\n",
        "        \"type\": \"text\",\n",
        "        \"copy_to\": \"overview_vector\"\n",
        "      },\n",
        "      \"overview_vector\": {\n",
        "        \"type\": \"semantic_text\"\n",
        "      }\n",
        "    }\n",
        "  }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abc3ee7a1fddfa9b",
      "metadata": {
        "collapsed": false,
        "id": "abc3ee7a1fddfa9b",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "Notice how we configured the mappings. We defined `overview_vector` as a `semantic_text` field.\n",
        "The `inference_id` parameter defines the inference endpoint that is used to generate the embeddings for the field.\n",
        "Then we configured the `overview` field to [copy its value](https://www.elastic.co/guide/en/elasticsearch/reference/current/copy-to.html) to the `overview_vector` field.\n",
        "\n",
        "While `copy_to` is not required to use `semantic_text`, it enables use cases like hybrid search where semantic and lexical techniques are used together. We will cover a hybrid search example later in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b5a46b60660a489",
      "metadata": {
        "collapsed": false,
        "id": "2b5a46b60660a489",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "## Populate the Index\n",
        "\n",
        "Let's populate the index with our example dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gPSoFx2I0_Wq",
      "metadata": {
        "id": "gPSoFx2I0_Wq"
      },
      "source": [
        "### Colab - Download Data - TODO update with real URL\n",
        "\n",
        "If running the notebook in Colab, as opposed to checking out or downloading the elasticsearch-labs repository, we need to download the data to the colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_Xz6xWOL1VZi",
      "metadata": {
        "id": "_Xz6xWOL1VZi"
      },
      "outputs": [],
      "source": [
        "!wget -O movies.json.gz https://github.com/mbrunnert/elasticsearch-labs/raw/refs/heads/ensuring-semantic-precision-with-minimum-score/supporting-blog-content/ensuring-semantic-precision-with-minimum-score/movies.json.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gZVKC1iM1Vm8",
      "metadata": {
        "id": "gZVKC1iM1Vm8"
      },
      "source": [
        "### Run data import script\n",
        "\n",
        "This will take a little while, probably around 15 minutes..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24f0133923553d28",
      "metadata": {
        "id": "24f0133923553d28",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "def data_generator(file_json, index):\n",
        "    for doc in file_json:\n",
        "        # doc[\"_run_ml_inference\"] = True\n",
        "        yield {\n",
        "            \"_index\": index,\n",
        "            \"_source\": doc,\n",
        "        }\n",
        "\n",
        "print(\"Indexing movies data, this might take a while...\")\n",
        "file = gzip.open('movies.json.gz', \"r\")\n",
        "json_bytes = file.read()\n",
        "json_str = json_bytes.decode(\"utf-8\")\n",
        "file_json = json.loads(json_str)\n",
        "total_documents = len(file_json)\n",
        "progress_bar = tqdm(total=total_documents, unit=\"documents\")\n",
        "success_count = 0\n",
        "\n",
        "\n",
        "for ok, info in helpers.streaming_bulk(\n",
        "    client=client,\n",
        "    chunk_size=16,\n",
        "    actions=data_generator(file_json, INDEX_NAME),\n",
        "    raise_on_error=True,\n",
        "):\n",
        "    if ok:\n",
        "        success_count += 1\n",
        "    else:\n",
        "        print(f\"Unable to index {info['index']['_id']}: {info['index']['error']}\")\n",
        "    progress_bar.update(1)\n",
        "    progress_bar.set_postfix(success=success_count)\n",
        "\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# Calculate the success percentage\n",
        "success_percentage = (success_count / total_documents) * 100\n",
        "print(f\"Indexing completed! Success percentage: {success_percentage}%\")\n",
        "print(\"Done indexing movies data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fff5932fcbac1b0",
      "metadata": {
        "collapsed": false,
        "id": "6fff5932fcbac1b0",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "## Semantic Search\n",
        "\n",
        "Now that our index is populated, we can query it using semantic search.\n",
        "\n",
        "### Aside: Pretty printing Elasticsearch search results\n",
        "\n",
        "Your `search` API calls will return hard-to-read nested JSON.\n",
        "We'll create a little function called `pretty_search_response` to return nice, human-readable outputs from our examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad417b4b3f50c889",
      "metadata": {
        "id": "ad417b4b3f50c889",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "def pretty_search_response(response):\n",
        "    if len(response[\"hits\"][\"hits\"]) == 0:\n",
        "        print(\"Your search returned no results.\")\n",
        "    else:\n",
        "      position = 1\n",
        "      for position,hit in enumerate(response[\"hits\"][\"hits\"], start=1):\n",
        "          id = hit[\"_id\"]\n",
        "          score = hit[\"_score\"]\n",
        "          title = hit[\"_source\"][\"title\"]\n",
        "          overview = hit[\"_source\"][\"overview\"]\n",
        "          rating = hit[\"_source\"].get(\"rating\", \"unknown\")\n",
        "\n",
        "          pretty_output = f\"\\nPosition: {position} Score: {score} ID: {id}\\nTitle: {title}\\nOverview: {overview}\\nRating: {rating}\"\n",
        "\n",
        "          print(pretty_output)\n",
        "          position = position + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22c4d4d395adb472",
      "metadata": {
        "collapsed": false,
        "id": "22c4d4d395adb472",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "### Semantic Search with the `semantic` Query\n",
        "\n",
        "We can use the [`semantic` query](https://www.elastic.co/guide/en/elasticsearch/reference/master/query-dsl-semantic-query.html) to quickly & easily query the `semantic_text` field in our index.\n",
        "Under the hood, an embedding is automatically generated for our query text using the `semantic_text` field's inference endpoint. Notice at the bottom of search results, some movies are not really super hero movies, such as Beethoven's 3rd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xGsmdeLbE8uE",
      "metadata": {
        "id": "xGsmdeLbE8uE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a8520ffc8a3efb3",
      "metadata": {
        "id": "1a8520ffc8a3efb3",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\"semantic\": {\"field\": \"overview_vector\", \"query\": \"superhero movie\"}},\n",
        "    size=100\n",
        ")\n",
        "\n",
        "pretty_search_response(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "148fda24a3964aa9",
      "metadata": {
        "collapsed": false,
        "id": "148fda24a3964aa9",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "\n",
        "We will now move on to increase the precision by introducing minimum score."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c9bab225a745746",
      "metadata": {
        "collapsed": false,
        "id": "7c9bab225a745746",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "### Normalising and Enforcing Minimum Score\n",
        "\n",
        "The below example adds the minimum score parameter to reduce irrelevant results. It utilises the minmax normalizer to get a nice score distribution of 0-1, which also helps in setting an appropriate score threshold. Feel free to experiment with different thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f72f7906b918dc1",
      "metadata": {
        "id": "4f72f7906b918dc1",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    size=100,\n",
        "    retriever={\n",
        "    \"linear\": {\n",
        "      \"rank_window_size\": 500,\n",
        "      \"min_score\": 0.25,\n",
        "      \"retrievers\": [\n",
        "        {\n",
        "          \"normalizer\": \"minmax\",\n",
        "          \"retriever\": {\n",
        "            \"standard\": {\n",
        "              \"query\": {\n",
        "                \"semantic\": {\n",
        "                  \"field\": \"overview_vector\",\n",
        "                  \"query\": \"superhero movie\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  }\n",
        ",\n",
        ")\n",
        "\n",
        "pretty_search_response(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d50d10ced4389107",
      "metadata": {
        "collapsed": false,
        "id": "d50d10ced4389107",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "These results demonstate how to cut-off the long tail of irrelavant results. Lets build on the semantic search retriever with a couple of hybrid search examples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q_rd45OvH9Xi",
      "metadata": {
        "id": "q_rd45OvH9Xi"
      },
      "source": [
        "## Hybrid Search Using Linear Retriever\n",
        "\n",
        "The below hybrid search request uses linear retriever with weights to control the importance of the semantic vs lexical search. Note that weights add up to 1, which means the total score will remain within the 0-1 interval. This will again make it easier to set and understand the minimum threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ISDPZ8bIHmuc",
      "metadata": {
        "id": "ISDPZ8bIHmuc"
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    size=100,\n",
        "    retriever={\n",
        "    \"linear\": {\n",
        "      \"rank_window_size\": 500,\n",
        "      \"min_score\": 0.25,\n",
        "      \"retrievers\": [\n",
        "        {\n",
        "          \"weight\": 0.6,\n",
        "          \"normalizer\": \"minmax\",\n",
        "          \"retriever\": {\n",
        "            \"standard\": {\n",
        "              \"query\": {\n",
        "                \"semantic\": {\n",
        "                  \"field\": \"overview_vector\",\n",
        "                  \"query\": \"superhero movie\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        },\n",
        "        {\n",
        "          \"weight\": 0.4,\n",
        "          \"normalizer\": \"minmax\",\n",
        "          \"retriever\": {\n",
        "            \"standard\": {\n",
        "              \"query\": {\n",
        "                \"multi_match\": {\n",
        "                  \"query\": \"superhero movie\",\n",
        "                  \"fields\": [\"overview\",\"keywords\", \"title\"],\n",
        "                  \"type\": \"cross_fields\",\n",
        "                  \"minimum_should_match\": \"2\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  }\n",
        ")\n",
        "\n",
        "pretty_search_response(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U96hNBR6I0OC",
      "metadata": {
        "id": "U96hNBR6I0OC"
      },
      "source": [
        "Note that in this case the minimum score is applied to the total score, not just the semantic score."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "li5fNhxqI78z",
      "metadata": {
        "id": "li5fNhxqI78z"
      },
      "source": [
        "## Hybrid Search Using RRF\n",
        "\n",
        "The below search uses RRF and applies the minimum score only to the semantic score. This allows us to control the semantic and lexical precision individually. To control lexical precision, we often use the minimum_should_match parameter, as in this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LaNnptAtJjy3",
      "metadata": {
        "id": "LaNnptAtJjy3"
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    size=100,\n",
        "    retriever={\n",
        "    \"rrf\": {\n",
        "      \"rank_window_size\": 500,\n",
        "      \"retrievers\": [\n",
        "        {\n",
        "          \"linear\": {\n",
        "            \"rank_window_size\": 500,\n",
        "            \"min_score\": 0.25,\n",
        "            \"retrievers\": [\n",
        "              {\n",
        "                \"normalizer\": \"minmax\",\n",
        "                \"retriever\": {\n",
        "                  \"standard\": {\n",
        "                    \"query\": {\n",
        "                      \"semantic\": {\n",
        "                        \"field\": \"overview_vector\",\n",
        "                        \"query\": \"superhero movie\"\n",
        "                      }\n",
        "                    }\n",
        "                  }\n",
        "                }\n",
        "              }\n",
        "            ]\n",
        "          }\n",
        "        },\n",
        "        {\n",
        "          \"standard\": {\n",
        "            \"query\": {\n",
        "              \"multi_match\": {\n",
        "                \"query\": \"superhero movie\",\n",
        "                \"fields\": [\"overview\", \"keywords\",\"title\"],\n",
        "                \"type\": \"cross_fields\",\n",
        "                \"minimum_should_match\": \"2\"\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  }\n",
        ")\n",
        "\n",
        "pretty_search_response(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78be304240d6c695",
      "metadata": {
        "collapsed": false,
        "id": "78be304240d6c695",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "We have shown how the minimum score parameter can be used to improve precision in search results, especially for semantic search. Feel free to experiment with different queries and min_score settings."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
