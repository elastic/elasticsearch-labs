{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGVterhZUeb7"
   },
   "source": [
    "\n",
    "\n",
    "# Multimodal RAG with Elasticsearch: The Gotham City Case\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGuNiw7hUc6M"
   },
   "source": [
    "This notebook implements the Multimodal RAG (Retrieval-Augmented Generation) pipeline with Elasticsearch as described in the blog. We follow the same structure as the article, with each section explained and implemented in code.\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "First, we need to clone the repository that contains the complete project code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UM5x0n2iA7o2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'elasticsearch-labs' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Clone do reposit√≥rio espec√≠fico com a branch feature/multimodal-rag-gotham\n",
    "!git clone -b feature/multimodal-rag-gotham https://github.com/salgado/elasticsearch-labs.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6mW8JNyVdzi"
   },
   "source": [
    "Let's navigate to the project directory where the necessary files are located:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PHrDQc0jOOb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jessgarson/elasticsearch-labs/supporting-blog-content/building-multimodal-rag-with-elasticsearch-gotham/notebook/elasticsearch-labs/supporting-blog-content/building-multimodal-rag-with-elasticsearch-gotham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd elasticsearch-labs/supporting-blog-content/building-multimodal-rag-with-elasticsearch-gotham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAGB159_Uaxb"
   },
   "source": [
    "Now let's configure the environment variables needed to connect to Elasticsearch and OpenAI. This is necessary for indexing and searching content, as well as generating the final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "U8IuJRQhS7lz"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the Elasticsearch endpoint url:  https://getting-started.es.us-east4.gcp.elastic-cloud.com\n",
      "Enter the Elasticsearch API key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "Enter the OpenAI API key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "ELASTICSEARCH_URL = input(\"Enter the Elasticsearch endpoint url: \")\n",
    "ELASTICSEARCH_API_KEY = getpass.getpass(\"Enter the Elasticsearch API key: \")\n",
    "OPENAI_API_KEY = getpass.getpass(\"Enter the OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZC4v_SHjMwLa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ELASTICSEARCH_API_KEY\"] = ELASTICSEARCH_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"ELASTICSEARCH_URL\"] = ELASTICSEARCH_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNRExs7aVl45"
   },
   "source": [
    "\n",
    "## Installing Dependencies\n",
    "\n",
    "As mentioned in the blog, we need to install the specific dependencies, including the custom ImageBind fork:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FhPcJYl03eNL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 2.1.0 not found\n",
      "Requirement already satisfied: opencv-python-headless in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pillow in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (11.1.0)\n",
      "Requirement already satisfied: numpy in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (2.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting git+https://github.com/hkchengrex/ImageBind.git\n",
      "  Cloning https://github.com/hkchengrex/ImageBind.git to /private/var/folders/z9/dz5wy_nd4_v1_gc8dg_5krqr0000gn/T/pip-req-build-4emj3jts\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/hkchengrex/ImageBind.git /private/var/folders/z9/dz5wy_nd4_v1_gc8dg_5krqr0000gn/T/pip-req-build-4emj3jts\n",
      "  Resolved https://github.com/hkchengrex/ImageBind.git to commit 9989650c87d393d7e8c144194182cbf124cd03a0\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorchvideo@ git+https://github.com/facebookresearch/pytorchvideo.git@ae9cfc6e62ca49eb9721a7a56e1e13e348ad21dc\n",
      "  Cloning https://github.com/facebookresearch/pytorchvideo.git (to revision ae9cfc6e62ca49eb9721a7a56e1e13e348ad21dc) to /private/var/folders/z9/dz5wy_nd4_v1_gc8dg_5krqr0000gn/T/pip-install-o1gm4gp6/pytorchvideo_2534250cb1054a59849875172f1b4d8a\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorchvideo.git /private/var/folders/z9/dz5wy_nd4_v1_gc8dg_5krqr0000gn/T/pip-install-o1gm4gp6/pytorchvideo_2534250cb1054a59849875172f1b4d8a\n",
      "  Running command git rev-parse -q --verify 'sha^ae9cfc6e62ca49eb9721a7a56e1e13e348ad21dc'\n",
      "  Running command git fetch -q https://github.com/facebookresearch/pytorchvideo.git ae9cfc6e62ca49eb9721a7a56e1e13e348ad21dc\n",
      "  Running command git checkout -q ae9cfc6e62ca49eb9721a7a56e1e13e348ad21dc\n",
      "  Resolved https://github.com/facebookresearch/pytorchvideo.git to commit ae9cfc6e62ca49eb9721a7a56e1e13e348ad21dc\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.13.1 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (2.6.0)\n",
      "Requirement already satisfied: timm>=1.0.12 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (1.0.15)\n",
      "Requirement already satisfied: numpy>=1.19 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (2.2.3)\n",
      "Requirement already satisfied: torchaudio in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (2.6.0)\n",
      "Requirement already satisfied: regex in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (2024.11.6)\n",
      "Requirement already satisfied: einops in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (0.8.1)\n",
      "Requirement already satisfied: matplotlib in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (3.10.0)\n",
      "Requirement already satisfied: types-regex in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (2024.11.6.20241221)\n",
      "Requirement already satisfied: torchvision in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (0.21.0)\n",
      "Requirement already satisfied: cartopy in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (0.24.1)\n",
      "Requirement already satisfied: iopath in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (0.1.10)\n",
      "Requirement already satisfied: fvcore in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (0.1.5.post20221221)\n",
      "Requirement already satisfied: ftfy in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from imagebind==1.0.0) (6.3.1)\n",
      "Requirement already satisfied: safetensors in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from timm>=1.0.12->imagebind==1.0.0) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from timm>=1.0.12->imagebind==1.0.0) (0.29.1)\n",
      "Requirement already satisfied: pyyaml in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from timm>=1.0.12->imagebind==1.0.0) (6.0.2)\n",
      "Requirement already satisfied: networkx in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch>=1.13.1->imagebind==1.0.0) (3.4.2)\n",
      "Requirement already satisfied: filelock in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch>=1.13.1->imagebind==1.0.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch>=1.13.1->imagebind==1.0.0) (4.12.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch>=1.13.1->imagebind==1.0.0) (1.13.1)\n",
      "Requirement already satisfied: fsspec in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch>=1.13.1->imagebind==1.0.0) (2025.2.0)\n",
      "Requirement already satisfied: jinja2 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch>=1.13.1->imagebind==1.0.0) (3.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.1->imagebind==1.0.0) (1.3.0)\n",
      "Requirement already satisfied: pyproj>=3.3.1 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from cartopy->imagebind==1.0.0) (3.7.1)\n",
      "Requirement already satisfied: packaging>=21 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from cartopy->imagebind==1.0.0) (24.2)\n",
      "Requirement already satisfied: shapely>=1.8 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from cartopy->imagebind==1.0.0) (2.0.7)\n",
      "Requirement already satisfied: pyshp>=2.3 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from cartopy->imagebind==1.0.0) (2.3.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib->imagebind==1.0.0) (11.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib->imagebind==1.0.0) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib->imagebind==1.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib->imagebind==1.0.0) (4.56.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib->imagebind==1.0.0) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib->imagebind==1.0.0) (3.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib->imagebind==1.0.0) (1.4.8)\n",
      "Requirement already satisfied: wcwidth in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ftfy->imagebind==1.0.0) (0.2.13)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from fvcore->imagebind==1.0.0) (0.1.8)\n",
      "Requirement already satisfied: tqdm in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from fvcore->imagebind==1.0.0) (4.67.1)\n",
      "Requirement already satisfied: termcolor>=1.1 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from fvcore->imagebind==1.0.0) (2.5.0)\n",
      "Requirement already satisfied: tabulate in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from fvcore->imagebind==1.0.0) (0.9.0)\n",
      "Requirement already satisfied: portalocker in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from iopath->imagebind==1.0.0) (3.1.1)\n",
      "Requirement already satisfied: av in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pytorchvideo@ git+https://github.com/facebookresearch/pytorchvideo.git@ae9cfc6e62ca49eb9721a7a56e1e13e348ad21dc->imagebind==1.0.0) (14.2.0)\n",
      "Requirement already satisfied: parameterized in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pytorchvideo@ git+https://github.com/facebookresearch/pytorchvideo.git@ae9cfc6e62ca49eb9721a7a56e1e13e348ad21dc->imagebind==1.0.0) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pyproj>=3.3.1->cartopy->imagebind==1.0.0) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->imagebind==1.0.0) (1.17.0)\n",
      "Requirement already satisfied: requests in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from huggingface_hub->timm>=1.0.12->imagebind==1.0.0) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from jinja2->torch>=1.13.1->imagebind==1.0.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests->huggingface_hub->timm>=1.0.12->imagebind==1.0.0) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests->huggingface_hub->timm>=1.0.12->imagebind==1.0.0) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests->huggingface_hub->timm>=1.0.12->imagebind==1.0.0) (3.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install base dependencies\n",
    "!pip install torch>=2.1.0 torchvision>=0.16.0 torchaudio>=2.1.0\n",
    "!pip install opencv-python-headless pillow numpy\n",
    "\n",
    "# Install the specific ImageBind fork\n",
    "!pip install git+https://github.com/hkchengrex/ImageBind.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LISqDRmE8PpG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GGIFHatG9BTP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (1.64.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: sniffio in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from soundfile) (2.2.3)\n",
      "Requirement already satisfied: pycparser in /Users/jessgarson/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJt01mAeYaOT"
   },
   "source": [
    "## Stage 1 - Collecting Crime Scene Clues\n",
    "\n",
    "As explained in the blog, the first step is to verify that we have the correct directory structure and that the evidence files are present. We use `files_check.py` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rZJexfwR4FaT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are correctly organized!\n"
     ]
    }
   ],
   "source": [
    "!python stages/01-stage/files_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a1tNsiGYjEZ"
   },
   "source": [
    "## Stage 2 - Generating Embeddings with ImageBind\n",
    "\n",
    "Now we test the embedding generation for an image using ImageBind. As the blog explains, ImageBind allows us to generate embeddings for different modalities (image, audio, text) in a shared vector space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A6C9IIuA6dlH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:embedding_generator:Testing model with sample input...\n",
      "INFO:embedding_generator:ü§ñ ImageBind model initialized successfully\n",
      "(1024,)\n"
     ]
    }
   ],
   "source": [
    "!python stages/02-stage/test_embedding_generation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vw5xlFXgYls4"
   },
   "source": [
    "This script generates a 1024-dimensional embedding for a test image, confirming that the ImageBind model is working correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2dsScL5ZF0X"
   },
   "source": [
    "\n",
    "## Stage 3 - Storage and Search in Elasticsearch\n",
    "\n",
    "### Content Indexing\n",
    "\n",
    "The next step is to index all multimodal evidence in Elasticsearch. This includes images, audio, text, and depth maps as described in the blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3nBsEf7u60bq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:embedding_generator:Testing model with sample input...\n",
      "INFO:embedding_generator:ü§ñ ImageBind model initialized successfully\n",
      "INFO:elastic_transport.transport:HEAD https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content [status:200 duration:0.092s]\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_doc [status:201 duration:0.102s]\n",
      "INFO:__main__:\n",
      "\n",
      "Indexed vision: {\n",
      "  \"result\": \"created\",\n",
      "  \"_id\": \"qBn_SJUBvmLH5RQPKxjd\",\n",
      "  \"_index\": \"multimodal_content\"\n",
      "}\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_doc [status:201 duration:0.049s]\n",
      "INFO:__main__:\n",
      "\n",
      "Indexed vision: {\n",
      "  \"result\": \"created\",\n",
      "  \"_id\": \"qRn_SJUBvmLH5RQPLhgX\",\n",
      "  \"_index\": \"multimodal_content\"\n",
      "}\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_doc [status:201 duration:0.045s]\n",
      "INFO:__main__:\n",
      "\n",
      "Indexed vision: {\n",
      "  \"result\": \"created\",\n",
      "  \"_id\": \"qhn_SJUBvmLH5RQPMBgk\",\n",
      "  \"_index\": \"multimodal_content\"\n",
      "}\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_doc [status:201 duration:0.037s]\n",
      "INFO:__main__:\n",
      "\n",
      "Indexed audio: {\n",
      "  \"result\": \"created\",\n",
      "  \"_id\": \"qxn_SJUBvmLH5RQPMRgX\",\n",
      "  \"_index\": \"multimodal_content\"\n",
      "}\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_doc [status:201 duration:0.050s]\n",
      "INFO:__main__:\n",
      "\n",
      "Indexed text: {\n",
      "  \"result\": \"created\",\n",
      "  \"_id\": \"rBn_SJUBvmLH5RQPMRjx\",\n",
      "  \"_index\": \"multimodal_content\"\n",
      "}\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_doc [status:201 duration:0.032s]\n",
      "INFO:__main__:\n",
      "\n",
      "Indexed text: {\n",
      "  \"result\": \"created\",\n",
      "  \"_id\": \"rRn_SJUBvmLH5RQPMhix\",\n",
      "  \"_index\": \"multimodal_content\"\n",
      "}\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_doc [status:201 duration:0.028s]\n",
      "INFO:__main__:\n",
      "\n",
      "Indexed depth: {\n",
      "  \"result\": \"created\",\n",
      "  \"_id\": \"rhn_SJUBvmLH5RQPMhj5\",\n",
      "  \"_index\": \"multimodal_content\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!python stages/03-stage/index_all_modalities.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tf-8U-CGZXxW"
   },
   "source": [
    "\n",
    "Each piece of evidence is now indexed in Elasticsearch with their respective embeddings, allowing for similarity search.\n",
    "\n",
    "### Searching by Similarity Across Different Modalities\n",
    "\n",
    "Now we can test searching for evidence by similarity using different modalities as queries. The blog describes how an input from one modality can retrieve results from all modalities.\n",
    "\n",
    "#### Search by Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7f-MBkFALphP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:embedding_generator:Testing model with sample input...\n",
      "INFO:embedding_generator:ü§ñ ImageBind model initialized successfully\n",
      "INFO:elastic_transport.transport:HEAD https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content [status:200 duration:0.172s]\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_search [status:200 duration:0.090s]\n",
      "\n",
      "üîé Similar evidence found:\n",
      "\n",
      "1. A sinister laugh captured near the crime scene (audio)\n",
      "   Similarity: 0.9987\n",
      "   File path: data/audios/joker_laugh.wav\n",
      "\n",
      "2. The Joker with green hair, white face paint, and a sinister smile in an urban night setting. (vision)\n",
      "   Similarity: 0.5708\n",
      "   File path: data/images/joker_laughing.png\n",
      "\n",
      "3. The Joker with green hair, white face paint, and a sinister smile in an urban night setting. (vision)\n",
      "   Similarity: 0.5666\n",
      "   File path: data/images/joker_laughing.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python stages/03-stage/search_by_audio.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrGUO1JVZZnz"
   },
   "source": [
    "\n",
    "This command uses an audio file as a query and retrieves the most similar evidence. In the case of Gotham, this helps identify connections between the audio of a sinister laugh and other evidence.\n",
    "\n",
    "#### Search by Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "mm_RwbfYQBGK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:embedding_generator:Testing model with sample input...\n",
      "INFO:embedding_generator:ü§ñ ImageBind model initialized successfully\n",
      "INFO:elastic_transport.transport:HEAD https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content [status:200 duration:0.121s]\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_search [status:200 duration:0.192s]\n",
      "\n",
      "üîé Similar evidence found:\n",
      "\n",
      "1. Mysterious note found at the location (text)\n",
      "   Similarity: 0.7639\n",
      "   File path: data/texts/riddle.txt\n",
      "\n",
      "2. Mysterious note found at the location (text)\n",
      "   Similarity: 0.7589\n",
      "   File path: data/texts/riddle.txt\n",
      "\n",
      "3. Mysterious note found at the location (text)\n",
      "   Similarity: 0.7589\n",
      "   File path: data/texts/riddle.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python stages/03-stage/search_by_text.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXhvE2EbZgQt"
   },
   "source": [
    "\n",
    "Here we use a text query (\"Why so serious?\") to find related evidence.\n",
    "\n",
    "#### Search by Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jrOBYZwtQQng"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:embedding_generator:Testing model with sample input...\n",
      "INFO:embedding_generator:ü§ñ ImageBind model initialized successfully\n",
      "INFO:elastic_transport.transport:HEAD https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content [status:200 duration:0.152s]\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_search [status:200 duration:0.081s]\n",
      "\n",
      "üîé Similar evidence found:\n",
      "\n",
      "1. Photo of the crime scene: A dark, rain-soaked alley is filled with playing cards, while a sinister graffiti of the Joker laughing stands out on the brick wall. (vision)\n",
      "   Similarity: 0.8258\n",
      "   File path: data/images/crime_scene1.jpg\n",
      "\n",
      "2. Photo of the crime scene: A dark, rain-soaked alley is filled with playing cards, while a sinister graffiti of the Joker laughing stands out on the brick wall. (vision)\n",
      "   Similarity: 0.8258\n",
      "   File path: data/images/crime_scene1.jpg\n",
      "\n",
      "3. Photo of the crime scene: A dark, rain-soaked alley is filled with playing cards, while a sinister graffiti of the Joker laughing stands out on the brick wall. (vision)\n",
      "   Similarity: 0.8258\n",
      "   File path: data/images/crime_scene1.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python stages/03-stage/search_by_image.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2Ut2whVZm3s"
   },
   "source": [
    "This script uses an image from the crime scene to find similar visual evidence.\n",
    "\n",
    "#### Search by Depth Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Bbm1vWfXQiPZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:embedding_generator:Testing model with sample input...\n",
      "INFO:embedding_generator:ü§ñ ImageBind model initialized successfully\n",
      "INFO:elastic_transport.transport:HEAD https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content [status:200 duration:0.168s]\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_search [status:200 duration:0.083s]\n",
      "\n",
      "üîé Similar evidence found:\n",
      "\n",
      "1. Photo of the crime scene: A dark, rain-soaked alley is filled with playing cards, while a sinister graffiti of the Joker laughing stands out on the brick wall. (vision)\n",
      "   Similarity: 0.5053\n",
      "   File path: data/images/crime_scene1.jpg\n",
      "\n",
      "2. Photo of the crime scene: A dark, rain-soaked alley is filled with playing cards, while a sinister graffiti of the Joker laughing stands out on the brick wall. (vision)\n",
      "   Similarity: 0.5053\n",
      "   File path: data/images/crime_scene1.jpg\n",
      "\n",
      "3. The Joker with green hair, white face paint, and a sinister smile in an urban night setting. (vision)\n",
      "   Similarity: 0.5006\n",
      "   File path: data/images/joker_laughing.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python stages/03-stage/search_by_depth.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWSzg742ZoQw"
   },
   "source": [
    "As explained in the blog, depth maps can provide information about the 3D structure of the scene or objects, complementing the other modalities.\n",
    "\n",
    "## Stage 4 - Evidence Analysis with LLM\n",
    "\n",
    "Finally, we bring together all the retrieved evidence and use an LLM (GPT-4) to generate a forensic report that identifies the suspect based on the connections between the different modalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "A8pmOH31Q2Hc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:embedding_generator:Testing model with sample input...\n",
      "INFO:embedding_generator:ü§ñ ImageBind model initialized successfully\n",
      "INFO:elastic_transport.transport:HEAD https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content [status:200 duration:0.101s]\n",
      "INFO:__main__:‚úÖ All components initialized successfully\n",
      "INFO:__main__:üîç Collecting evidence...\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_search [status:200 duration:0.097s]\n",
      "INFO:__main__:‚úÖ Data retrieved for vision: 2 results\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_search [status:200 duration:0.024s]\n",
      "INFO:__main__:‚úÖ Data retrieved for audio: 2 results\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_search [status:200 duration:0.025s]\n",
      "INFO:__main__:‚úÖ Data retrieved for text: 2 results\n",
      "INFO:elastic_transport.transport:POST https://getting-started.es.us-east4.gcp.elastic-cloud.com:443/multimodal_content/_search [status:200 duration:0.025s]\n",
      "INFO:__main__:‚úÖ Data retrieved for depth: 2 results\n",
      "INFO:__main__:\n",
      "üìù Generating forensic report...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llm_analyzer:\n",
      "üìã Forensic Report Generated:\n",
      "INFO:llm_analyzer:==================================================\n",
      "INFO:llm_analyzer:**Prime Suspect:** The Joker\n",
      "\n",
      "**Evidence Supporting Conclusion:**\n",
      "\n",
      "- **Visual Evidence:** The crime scene photos are highly indicative of the Joker's involvement. The presence of playing cards scattered around a dark, rain-soaked alley and the sinister graffiti of the Joker laughing on a brick wall align closely with the Joker's known penchant for leaving thematic calling cards at his crime scenes. The similarity score of 0.83 for both photos suggests a high degree of confidence in the visual match to known Joker-related crime scenes.\n",
      "\n",
      "- **Auditory Evidence:** The captured audio of a sinister laugh near the crime scene, with a similarity score of 1.00, directly points to the Joker. His distinctive laugh is a well-documented auditory signature that he leaves at the scenes of his crimes, serving both as a psychological weapon and a marker of his presence.\n",
      "\n",
      "- **Textual Evidence:** The mysterious note found at the location, with a similarity score of 0.76, suggests it may contain a message or riddle typical of the Joker's communication style. While the exact content of the note is not detailed, the Joker is known for leaving taunting messages for the authorities and Batman, often as part of his chaotic schemes.\n",
      "\n",
      "- **Depth Evidence:** The depth sensor capture of the suspect, with a similarity score of 0.77, indicates a figure that matches the Joker's known physical profile or one of his disguises. While depth sensor data alone might not conclusively identify a suspect due to the lack of facial features or detailed physical markers, in conjunction with the other evidence, it supports the conclusion.\n",
      "\n",
      "**Behavioral Patterns:**\n",
      "\n",
      "The Joker's criminal signature is evident in the combination of thematic elements (playing cards, laughter), his method of taunting authorities with notes, and the choice of crime scenes that reflect his chaotic and theatrical nature. His motives often revolve around creating chaos, drawing Batman out, and demonstrating his intellectual superiority through complex schemes. The evidence collected aligns with these known patterns and motives.\n",
      "\n",
      "**Confidence Level:** 95%\n",
      "\n",
      "The evidence strongly suggests the Joker's involvement, with high similarity scores across visual and auditory data, and moderate confidence in the textual and depth evidence. The slight deduction in confidence accounts for the inherent limitations in depth sensor identification without facial recognition and the indirect nature of textual evidence.\n",
      "\n",
      "**Next Steps:** No further evidence required.\n",
      "\n",
      "The combination of multimodal evidence provides a comprehensive profile that matches the Joker's known criminal behavior and modus operandi. While additional evidence could always further solidify the case, the current dataset is sufficient to justify focusing investigative and apprehension efforts on the Joker.\n",
      "INFO:llm_analyzer:==================================================\n",
      "INFO:__main__:‚úÖ Forensic report generated successfully\n",
      "INFO:__main__:\n",
      "üìä Report Preview:\n",
      "INFO:__main__:++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "INFO:__main__:**Prime Suspect:** The Joker\n",
      "\n",
      "**Evidence Supporting Conclusion:**\n",
      "\n",
      "- **Visual Evidence:** The crime scene photos are highly indicative of the Joker's involvement. The presence of playing cards scattered around a dark, rain-soaked alley and the sinister graffiti of the Joker laughing on a brick wall align closely with the Joker's known penchant for leaving thematic calling cards at his crime scenes. The similarity score of 0.83 for both photos suggests a high degree of confidence in the visual match to known Joker-related crime scenes.\n",
      "\n",
      "- **Auditory Evidence:** The captured audio of a sinister laugh near the crime scene, with a similarity score of 1.00, directly points to the Joker. His distinctive laugh is a well-documented auditory signature that he leaves at the scenes of his crimes, serving both as a psychological weapon and a marker of his presence.\n",
      "\n",
      "- **Textual Evidence:** The mysterious note found at the location, with a similarity score of 0.76, suggests it may contain a message or riddle typical of the Joker's communication style. While the exact content of the note is not detailed, the Joker is known for leaving taunting messages for the authorities and Batman, often as part of his chaotic schemes.\n",
      "\n",
      "- **Depth Evidence:** The depth sensor capture of the suspect, with a similarity score of 0.77, indicates a figure that matches the Joker's known physical profile or one of his disguises. While depth sensor data alone might not conclusively identify a suspect due to the lack of facial features or detailed physical markers, in conjunction with the other evidence, it supports the conclusion.\n",
      "\n",
      "**Behavioral Patterns:**\n",
      "\n",
      "The Joker's criminal signature is evident in the combination of thematic elements (playing cards, laughter), his method of taunting authorities with notes, and the choice of crime scenes that reflect his chaotic and theatrical nature. His motives often revolve around creating chaos, drawing Batman out, and demonstrating his intellectual superiority through complex schemes. The evidence collected aligns with these known patterns and motives.\n",
      "\n",
      "**Confidence Level:** 95%\n",
      "\n",
      "The evidence strongly suggests the Joker's involvement, with high similarity scores across visual and auditory data, and moderate confidence in the textual and depth evidence. The slight deduction in confidence accounts for the inherent limitations in depth sensor identification without facial recognition and the indirect nature of textual evidence.\n",
      "\n",
      "**Next Steps:** No further evidence required.\n",
      "\n",
      "The combination of multimodal evidence provides a comprehensive profile that matches the Joker's known criminal behavior and modus operandi. While additional evidence could always further solidify the case, the current dataset is sufficient to justify focusing investigative and apprehension efforts on the Joker.\n",
      "INFO:__main__:++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "!python stages/04-stage/rag_crime_analyze.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaWriUfjZyUz"
   },
   "source": [
    "\n",
    "This is the final step of the Multimodal RAG pipeline, where the LLM analyzes the evidence retrieved from Elasticsearch and synthesizes it into a coherent report that identifies the Joker as the main suspect.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "We have thus completed the implementation of the complete Multimodal RAG pipeline with Elasticsearch, following all the steps described in the blog. This pipeline demonstrates how different types of media can be analyzed in an integrated way to provide richer insights and connections between evidence that would be difficult to identify manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
