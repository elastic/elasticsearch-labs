{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install -qU langchain elasticsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import modules\n",
    "from getpass import getpass\n",
    "from langchain.vectorstores import ElasticsearchStore\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "\n",
    "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key\n",
    "ELASTIC_API_KEY = getpass(\"Elastic Api Key: \")\n",
    "\n",
    "# https://platform.openai.com/api-keys\n",
    "OPENAI_API_KEY = getpass(\"OpenAI API key: \")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "vector_store = ElasticsearchStore(\n",
    "  es_cloud_id=ELASTIC_CLOUD_ID, \n",
    "  es_api_key=ELASTIC_API_KEY,\n",
    "  index_name= \"workplace_index\", \n",
    "  embedding=embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def parent_child_splitter(data, id_key=PARENT_DOC_ID_KEY):\n",
    "    parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "    # This text splitter is used to create the child documents\n",
    "    # It should create documents smaller than the parent\n",
    "    child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "    documents = parent_splitter.split_documents(data)\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in documents]\n",
    "\n",
    "    docs = []\n",
    "    for i, doc in enumerate(documents):\n",
    "        _id = doc_ids[i]\n",
    "        sub_docs = child_splitter.split_documents([doc])\n",
    "        for _doc in sub_docs:\n",
    "            _doc.metadata[id_key] = _id\n",
    "            _doc.metadata[\"doc_level\"] = \"child\"\n",
    "        docs.extend(sub_docs)\n",
    "        doc.metadata[id_key] = _id\n",
    "        doc.metadata[\"doc_level\"] = \"parent\"\n",
    "    return documents, docs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
