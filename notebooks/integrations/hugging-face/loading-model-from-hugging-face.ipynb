{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models into Elasticsearch from Hugging Face\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/colab-notebooks-examples/integrations/hugging-face/loading-model-from-hugging-face.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This interactive notebook uses eland to load machine learning models from the Hugging Face hub into an Elasticsearch deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "\n",
    "To get started we'll need to connect to our Elasticsearch deployment using the Python client.\n",
    "\n",
    "First we need to install our dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU elasticsearch eland torch transformers sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Elastic Cloud deployment\n",
    "\n",
    "If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?fromURI=%2Fhome) for a free trial.\n",
    "\n",
    "- Go to the [Create deployment](https://cloud.elastic.co/deployments/create) page\n",
    "- Select **Create deployment**\n",
    "\n",
    "Now we can instantiate the [Elasticsearch python client](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.html), providing the cloud id and password in your deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'e5f4d36cef4a', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'pvSmoDFzQA26HNRZe__RTw', 'version': {'number': '8.10.0-SNAPSHOT', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '92440687c5c05040596ad6c0383e0d91d42765a9', 'build_date': '2023-07-31T11:19:15.256884445Z', 'build_snapshot': True, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    # \"http://deployment_url\",\n",
    "    cloud_id=\"CLOUD_ID\",\n",
    "    basic_auth=(\"elastic\", \"PASSWORD\")\n",
    "    # api_key=\"API_KEY\"\n",
    ")\n",
    "\n",
    "# Test client to ensure you can connect\n",
    "print(es_client.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a Model from Hugging Face\n",
    "\n",
    "To import a model from Hugging face you will first need to find the model's id and task type so that it can be loaded into your Elasticsearch cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from eland.ml.pytorch import PyTorchModel\n",
    "from eland.ml.pytorch.transformers import TransformerModel\n",
    "\n",
    "# Load model from Hugging Face\n",
    "model_name = \"elastic/distilbert-base-cased-finetuned-conll03-english\" \n",
    "model_type = \"ner\"\n",
    "tm = TransformerModel(model_name, model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model\n",
    "\n",
    "We will create a directory where we can export the mode from Hugging Face to a Torchscript that can be imported to Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Export the model to a TorchScript representation which Elasticsearch uses\n",
    "tmp_path = \"models\"\n",
    "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
    "model_path, config, vocab_path = tm.save(tmp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model\n",
    "\n",
    "We will now import the model into Elasticsearch from the saved Torchscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db073032137945638f07ab5d7f17066a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ? parts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from eland.ml.pytorch import PyTorchModel\n",
    "\n",
    "# Import model into Elasticsearch\n",
    "model_id = tm.elasticsearch_model_id()\n",
    "ptm = PyTorchModel(es_client, model_id)\n",
    "\n",
    "# You can also give the model a custom model id like\n",
    "# ptm = PyTorchModel(es_client, \"my_model_id\")\n",
    "\n",
    "ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get trained models\n",
    "\n",
    "Next lets retrieve the list of trained models from Elasticsearch to ensure the model we imported is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_id\": \"elastic__distilbert-base-cased-finetuned-conll03-english\",\n",
      "  \"model_type\": \"pytorch\",\n",
      "  \"created_by\": \"api_user\",\n",
      "  \"version\": \"8.10.0\",\n",
      "  \"create_time\": 1690992040049,\n",
      "  \"model_size_bytes\": 0,\n",
      "  \"estimated_operations\": 0,\n",
      "  \"license_level\": \"platinum\",\n",
      "  \"description\": \"Model elastic/distilbert-base-cased-finetuned-conll03-english for task type 'ner'\",\n",
      "  \"tags\": [],\n",
      "  \"input\": {\n",
      "    \"field_names\": [\n",
      "      \"text_field\"\n",
      "    ]\n",
      "  },\n",
      "  \"inference_config\": {\n",
      "    \"ner\": {\n",
      "      \"vocabulary\": {\n",
      "        \"index\": \".ml-inference-native-000001\"\n",
      "      },\n",
      "      \"tokenization\": {\n",
      "        \"bert\": {\n",
      "          \"do_lower_case\": false,\n",
      "          \"with_special_tokens\": true,\n",
      "          \"max_sequence_length\": 512,\n",
      "          \"truncate\": \"first\",\n",
      "          \"span\": -1\n",
      "        }\n",
      "      },\n",
      "      \"classification_labels\": [\n",
      "        \"O\",\n",
      "        \"B_PER\",\n",
      "        \"I_PER\",\n",
      "        \"B_ORG\",\n",
      "        \"I_ORG\",\n",
      "        \"B_LOC\",\n",
      "        \"I_LOC\",\n",
      "        \"B_MISC\",\n",
      "        \"I_MISC\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"location\": {\n",
      "    \"index\": {\n",
      "      \"name\": \".ml-inference-native-000001\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "models_resp = es_client.ml.get_trained_models()\n",
    "\n",
    "for model_config in models_resp.body[\"trained_model_configs\"]:\n",
    "    if model_config[\"model_id\"] == model_id:\n",
    "        print(json.dumps(model_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start model deployment\n",
    "\n",
    "Finally we will start the trained model. You can [learn more](https://www.elastic.co/guide/en/elasticsearch/reference/current/start-trained-model-deployment.html) about starting the model in the machine learning API documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'status_exception', 'Could not start model deployment because an existing deployment with the same id [elastic__distilbert-base-cased-finetuned-conll03-english] exist')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m start_resp \u001b[38;5;241m=\u001b[39m \u001b[43mes_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_trained_model_deployment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpriority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnormal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber_of_allocations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads_per_allocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 1, 2, 4, 8, 16\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstarted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(start_resp\u001b[38;5;241m.\u001b[39mbody,indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/Code/elastic/elasticsearch-labs/.venv/lib/python3.11/site-packages/elasticsearch/_sync/client/utils.py:414\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/elastic/elasticsearch-labs/.venv/lib/python3.11/site-packages/elasticsearch/_sync/client/ml.py:3791\u001b[0m, in \u001b[0;36mMlClient.start_trained_model_deployment\u001b[0;34m(self, model_id, cache_size, error_trace, filter_path, human, number_of_allocations, pretty, priority, queue_capacity, threads_per_allocation, timeout, wait_for)\u001b[0m\n\u001b[1;32m   3789\u001b[0m     __query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m wait_for\n\u001b[1;32m   3790\u001b[0m __headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m-> 3791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   3792\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\n\u001b[1;32m   3793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/elastic/elasticsearch-labs/.venv/lib/python3.11/site-packages/elasticsearch/_sync/client/_base.py:389\u001b[0m, in \u001b[0;36mNamespacedClient.perform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    380\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Use the internal clients .perform_request() implementation\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# so we take advantage of their transport options.\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/elastic/elasticsearch-labs/.venv/lib/python3.11/site-packages/elasticsearch/_sync/client/_base.py:320\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(meta\u001b[38;5;241m.\u001b[39mstatus, ApiError)(\n\u001b[1;32m    321\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage, meta\u001b[38;5;241m=\u001b[39mmeta, body\u001b[38;5;241m=\u001b[39mresp_body\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verified_elasticsearch:\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;66;03m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: BadRequestError(400, 'status_exception', 'Could not start model deployment because an existing deployment with the same id [elastic__distilbert-base-cased-finetuned-conll03-english] exist')"
     ]
    }
   ],
   "source": [
    "start_resp = es_client.ml.start_trained_model_deployment(\n",
    "    model_id=model_id, \n",
    "    priority=\"normal\",\n",
    "    number_of_allocations=1,\n",
    "    threads_per_allocation=1, # 1, 2, 4, 8, 16\n",
    "    wait_for=\"started\",\n",
    "    timeout=\"1m\"\n",
    ")\n",
    "\n",
    "print(json.dumps(start_resp.body,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
