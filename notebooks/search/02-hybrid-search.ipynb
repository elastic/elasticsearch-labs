{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "s49gpkvZ7q53"
   },
   "source": [
    "# Hybrid Search using RRF\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/search/02-hybrid-search.ipynb)\n",
    "\n",
    "In this example we'll use the reciprocal rank fusion algorithm to combine the results of BM25 and kNN semantic search.\n",
    "We'll use the same dataset we used in our [quickstart](https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/search/00-quick-start.ipynb) guide.\n",
    "You can use RRF for hybrid search out of the box, without any additional configuration.\n",
    "\n",
    "We also provide a walkthrough of a toy example, which demonstrates how RRF ranking works at a basic level."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Y01AXpELkygt"
   },
   "source": [
    "# 🧰 Requirements\n",
    "\n",
    "For this example, you will need:\n",
    "\n",
    "- An Elastic deployment with minimum **4GB machine learning node**\n",
    "   - We'll be using [Elastic Cloud](https://www.elastic.co/guide/en/cloud/current/ec-getting-started.html) for this example (available with a [free trial](https://cloud.elastic.co/registration?elektra=en-ess-sign-up-page))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "N4pI1-eIvWrI"
   },
   "source": [
    "# Create Elastic Cloud deployment\n",
    "\n",
    "If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?fromURI=%2Fhome) for a free trial.\n",
    "\n",
    "- Go to the [Create deployment](https://cloud.elastic.co/deployments/create) page\n",
    "   - Under **Advanced settings**, go to **Machine Learning instances**\n",
    "   - You'll need at least **4GB** RAM per zone for this tutorial\n",
    "   - Select **Create deployment**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gaTFHLJC-Mgi"
   },
   "source": [
    "# Install packages and initialize the Elasticsearch Python client\n",
    "\n",
    "To get started, we'll need to connect to our Elastic deployment using the Python client.\n",
    "Because we're using an Elastic Cloud deployment, we'll use the **Cloud ID** to identify our deployment.\n",
    "\n",
    "First we need to `pip` install the packages we need for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9Q1p2C9-wce",
    "outputId": "204d5aee-571e-4363-be6e-f87d058f2d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "zsh:1: 8.9.0 not found\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: sentence_transformers in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sentence_transformers) (4.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sentence_transformers) (1.24.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sentence_transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.30.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n",
      "Requirement already satisfied: click in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from torchvision->sentence_transformers) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: torch in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch>=8.9.0\n",
    "!pip install sentence_transformers\n",
    "!pip install torch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gEzq2Z1wBs3M"
   },
   "source": [
    "Next we need to import the `elasticsearch` module and the `getpass` module.\n",
    "`getpass` is part of the Python standard library and is used to securely prompt for credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uP_GTVRi-d96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joe/.pyenv/versions/3.10.3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from urllib.request import urlopen\n",
    "import getpass\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AMSePFiZCRqX"
   },
   "source": [
    "Now we can instantiate the Python Elasticsearch client.\n",
    "First we prompt the user for their password and Cloud ID.\n",
    "\n",
    "🔐 NOTE: `getpass` enables us to securely prompt the user for credentials without echoing them to the terminal, or storing it in memory.\n",
    "\n",
    "Then we create a `client` object that instantiates an instance of the `Elasticsearch` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0MdAZ53CdKL",
    "outputId": "96ea6f81-f935-4d51-c4a7-af5a896180f1"
   },
   "outputs": [],
   "source": [
    "# Found in the 'Manage Deployment' page\n",
    "CLOUD_ID = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
    "\n",
    "# Password for the 'elastic' user generated by Elasticsearch\n",
    "ELASTIC_PASSWORD = getpass.getpass('Enter Elastic password:  ')\n",
    "\n",
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    cloud_id=CLOUD_ID,\n",
    "    basic_auth=(\"elastic\", ELASTIC_PASSWORD)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bRHbecNeEDL3"
   },
   "source": [
    "Confirm that the client has connected with this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdiUKqZbEKfF",
    "outputId": "43b6f1cd-a43e-4dbe-caa5-7fd170464881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'instance-0000000007', 'cluster_name': 'd1bd36862ce54c7b903e2aacd4cd7f0a', 'cluster_uuid': 'tIkh0X_UQKmMFQKSfUw-VQ', 'version': {'number': '8.9.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '8aa461beb06aa0417a231c345a1b8c38fb498a0d', 'build_date': '2023-07-19T14:43:58.555259655Z', 'build_snapshot': False, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "print(client.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "enHQuT57DhD1"
   },
   "source": [
    "Refer to https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect to a self-managed deployment.\n",
    "\n",
    "Read https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect using API keys.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TF_wxIAhD07a"
   },
   "source": [
    "# Create Elasticsearch index with required mappings\n",
    "\n",
    "We need to add a field to support dense vector storage and search.\n",
    "Note the `title_vector` field below, which is used to store the dense vector representation of the `title` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvYECABJJs_2",
    "outputId": "18fb51e4-c4f6-4d1b-cb2d-bc6f8ec1aa84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'rrf_book_index'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the index\n",
    "client.indices.create(\n",
    "    index='rrf_book_index', \n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"authors\": {\"type\": \"keyword\"},\n",
    "            \"summary\": {\"type\": \"text\"},\n",
    "            \"publish_date\": {\"type\": \"date\"},\n",
    "            \"num_reviews\": {\"type\": \"integer\"},\n",
    "            \"publisher\": {\"type\": \"keyword\"},\n",
    "            \"title_vector\": { \n",
    "                \"type\": \"dense_vector\", \n",
    "                \"dims\": 384, \n",
    "                \"index\": \"true\", \n",
    "                \"similarity\": \"dot_product\" \n",
    "            }\n",
    "        }\n",
    "    })\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Let's index some data.\n",
    "Note that we are embedding the `title` field using the sentence transformer model.\n",
    "Once indexed, you'll see that your documents contain a `title_vector` field (`\"type\": \"dense_vector\"`) which contains a vector of floating point values.\n",
    "This is the embedding of the `title` field in vector space.\n",
    "We'll use this field to perform semantic search using kNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = [\n",
    "    {\n",
    "        \"title\": \"The Pragmatic Programmer: Your Journey to Mastery\",\n",
    "        \"authors\": [\"andrew hunt\", \"david thomas\"],\n",
    "        \"summary\": \"A guide to pragmatic programming for software engineers and developers\",\n",
    "        \"publish_date\": \"2019-10-29\",\n",
    "        \"num_reviews\": 30,\n",
    "        \"publisher\": \"addison-wesley\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Python Crash Course\",\n",
    "        \"authors\": [\"eric matthes\"],\n",
    "        \"summary\": \"A fast-paced, no-nonsense guide to programming in Python\",\n",
    "        \"publish_date\": \"2019-05-03\",\n",
    "        \"num_reviews\": 42,\n",
    "        \"publisher\": \"no starch press\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Artificial Intelligence: A Modern Approach\",\n",
    "        \"authors\": [\"stuart russell\", \"peter norvig\"],\n",
    "        \"summary\": \"Comprehensive introduction to the theory and practice of artificial intelligence\",\n",
    "        \"publish_date\": \"2020-04-06\",\n",
    "        \"num_reviews\": 39,\n",
    "        \"publisher\": \"pearson\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Clean Code: A Handbook of Agile Software Craftsmanship\",\n",
    "        \"authors\": [\"robert c. martin\"],\n",
    "        \"summary\": \"A guide to writing code that is easy to read, understand and maintain\",\n",
    "        \"publish_date\": \"2008-08-11\",\n",
    "        \"num_reviews\": 55,\n",
    "        \"publisher\": \"prentice hall\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"You Don't Know JS: Up & Going\",\n",
    "        \"authors\": [\"kyle simpson\"],\n",
    "        \"summary\": \"Introduction to JavaScript and programming as a whole\",\n",
    "        \"publish_date\": \"2015-03-27\",\n",
    "        \"num_reviews\": 36,\n",
    "        \"publisher\": \"oreilly\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Eloquent JavaScript\",\n",
    "        \"authors\": [\"marijn haverbeke\"],\n",
    "        \"summary\": \"A modern introduction to programming\",\n",
    "        \"publish_date\": \"2018-12-04\",\n",
    "        \"num_reviews\": 38,\n",
    "        \"publisher\": \"no starch press\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Design Patterns: Elements of Reusable Object-Oriented Software\",\n",
    "        \"authors\": [\"erich gamma\", \"richard helm\", \"ralph johnson\", \"john vlissides\"],\n",
    "        \"summary\": \"Guide to design patterns that can be used in any object-oriented language\",\n",
    "        \"publish_date\": \"1994-10-31\",\n",
    "        \"num_reviews\": 45,\n",
    "        \"publisher\": \"addison-wesley\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Clean Coder: A Code of Conduct for Professional Programmers\",\n",
    "        \"authors\": [\"robert c. martin\"],\n",
    "        \"summary\": \"A guide to professional conduct in the field of software engineering\",\n",
    "        \"publish_date\": \"2011-05-13\",\n",
    "        \"num_reviews\": 20,\n",
    "        \"publisher\": \"prentice hall\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"JavaScript: The Good Parts\",\n",
    "        \"authors\": [\"douglas crockford\"],\n",
    "        \"summary\": \"A deep dive into the parts of JavaScript that are essential to writing maintainable code\",\n",
    "        \"publish_date\": \"2008-05-15\",\n",
    "        \"num_reviews\": 51,\n",
    "        \"publisher\": \"oreilly\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Introduction to the Theory of Computation\",\n",
    "        \"authors\": [\"michael sipser\"],\n",
    "        \"summary\": \"Introduction to the theory of computation and complexity theory\",\n",
    "        \"publish_date\": \"2012-06-27\",\n",
    "        \"num_reviews\": 33,\n",
    "        \"publisher\": \"cengage learning\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index documents\n",
    "\n",
    "Our dataset is a Python list that contains dictionaries of movie titles and descriptions.\n",
    "We'll use the `helpers.bulk` method to index our documents in batches.\n",
    "\n",
    "The following code iterates over the list of books and creates a list of actions to be performed.\n",
    "Each action is a dictionary containing an \"index\" operation on our Elasticsearch index.\n",
    "The book's title is encoded using our selected model, and the encoded vector is added to the book document.\n",
    "The book document is then added to the list of actions.\n",
    "\n",
    "Finally, we call the `bulk` method, specifying the index name and the list of actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 61, 'errors': False, 'items': [{'index': {'_index': 'rrf_book_index', '_id': 'W72R-YkBh2PvFlUSVfHi', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'XL2R-YkBh2PvFlUSVfHi', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 1, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'Xb2R-YkBh2PvFlUSVfHi', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 2, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'Xr2R-YkBh2PvFlUSVfHi', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 3, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'X72R-YkBh2PvFlUSVfHi', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 4, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'YL2R-YkBh2PvFlUSVfHi', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 5, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'Yb2R-YkBh2PvFlUSVfHi', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 6, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'Yr2R-YkBh2PvFlUSVfHi', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 7, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'Y72R-YkBh2PvFlUSVfHi', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 8, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'ZL2R-YkBh2PvFlUSVfHi', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 9, '_primary_term': 1, 'status': 201}}]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = []\n",
    "for book in books:\n",
    "    actions.append({\"index\": {\"_index\": \"rrf_book_index\"}})\n",
    "    titleEmbedding = model.encode(book[\"title\"]).tolist()\n",
    "    book[\"title_vector\"] = titleEmbedding\n",
    "    actions.append(book)\n",
    "\n",
    "client.bulk(index=\"rrf_book_index\", operations=actions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WgWDMgf9NkHL"
   },
   "source": [
    "## Pretty printing Elasticsearch responses\n",
    "\n",
    "This is a helper function to print Elasticsearch responses in a readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_response(response):\n",
    "    for hit in response['hits']['hits']:\n",
    "        id = hit['_id']\n",
    "        publication_date = hit['_source']['publish_date']\n",
    "        rank = hit['_rank']\n",
    "        title = hit['_source']['title']\n",
    "        summary = hit['_source']['summary']\n",
    "        pretty_output = (f\"\\nID: {id}\\nPublication date: {publication_date}\\nTitle: {title}\\nSummary: {summary}\\nRank: {rank}\")\n",
    "        print(pretty_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MrBCHdH1u8Wd"
   },
   "source": [
    "# Querying Documents with Hybrid Search\n",
    "\n",
    "Now we need to perform a query using two different search strategies:\n",
    "- Semantic search using the \"all-MiniLM-L6-v2\" embedding model\n",
    "- Keyword search using the \"title\" field\n",
    "\n",
    "We then use [Reciprocal Rank Fusion (RRF)](https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html) to balance the scores to provide a final list of documents, ranked in order of relevance. RRF is a ranking algorithm for combining results from different information retrieval strategies.\n",
    "\n",
    "**NOTE** Note that _score is null, and we instead use _rank to show our top-ranked documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID: XL2R-YkBh2PvFlUSVfHi\n",
      "Publication date: 2019-05-03\n",
      "Title: Python Crash Course\n",
      "Summary: A fast-paced, no-nonsense guide to programming in Python\n",
      "Rank: 1\n",
      "\n",
      "ID: W72R-YkBh2PvFlUSVfHi\n",
      "Publication date: 2019-10-29\n",
      "Title: The Pragmatic Programmer: Your Journey to Mastery\n",
      "Summary: A guide to pragmatic programming for software engineers and developers\n",
      "Rank: 2\n",
      "\n",
      "ID: YL2R-YkBh2PvFlUSVfHi\n",
      "Publication date: 2018-12-04\n",
      "Title: Eloquent JavaScript\n",
      "Summary: A modern introduction to programming\n",
      "Rank: 3\n",
      "\n",
      "ID: X72R-YkBh2PvFlUSVfHi\n",
      "Publication date: 2015-03-27\n",
      "Title: You Don't Know JS: Up & Going\n",
      "Summary: Introduction to JavaScript and programming as a whole\n",
      "Rank: 4\n",
      "\n",
      "ID: ZL2R-YkBh2PvFlUSVfHi\n",
      "Publication date: 2012-06-27\n",
      "Title: Introduction to the Theory of Computation\n",
      "Summary: Introduction to the theory of computation and complexity theory\n",
      "Rank: 5\n"
     ]
    }
   ],
   "source": [
    "response = client.search(\n",
    "    index=\"rrf_book_index\", \n",
    "    size=5, \n",
    "    query={\n",
    "        \"match\": {\n",
    "            \"summary\": \"python programming\"\n",
    "        }\n",
    "    }, \n",
    "    knn={\n",
    "        \"field\": \"title_vector\",\n",
    "        \"query_vector\" : model.encode(\"python programming\").tolist(), # generate embedding for query so it can be compared to `title_vector`\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10\n",
    "    },\n",
    "    rank={\n",
    "        \"rrf\": {}\n",
    "    }\n",
    ")\n",
    "\n",
    "pretty_response(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
